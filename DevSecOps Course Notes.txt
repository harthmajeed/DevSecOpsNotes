Practical DevSecOps Course Notes

Welcome To Practical DevSecOps Labs
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp


DevSecOps Gospel
1.	Maintain cordial relationships with Developers/QA and Operation teams
2.	Do not fail builds unless you are at maturity level 3 or 4
3.	Do not run any tool which takes more than 10 minutes in CI/CD pipelines
4.	Create separate jobs for each tool/scan
5.	Roll out tools/scans in phases (iteratively) even when critical/high severity issues are found
6.	Do not buy tools that does not provide APIs or CLIs
7.	Appreciate a vendor offering a per-use licensing model deeply and wholeheartedly
8.	Verify if the tool vendors support incremental/baseline scans
9.	Create SAST/DAST custom rule sets. Tools are of no use without creating custom rules/tweaks down the line
10.	Do Everything as Code (EaC) to provide the audit-ability, measurability, and security
11.	Do False Positives as Code to control scope of the scans
12.	Link tool wiki in the pipeline as a comment for sharing your team’s expertise with others




----Introduction to the Tools of the Trade----
DevSecOps-Box	devsecops-box-8lw53ql9	Expires when Lab timer closes
Git server	gitlab-ce-8lw53ql9	2 hours
CI/CD	gitlab-ce-8lw53ql9	2 hours
Prod	prod-8lw53ql9	2 hours
Vulnerability Management	dojo-8lw53ql9	2 hours

hostname
ping -c 3 prod-8lw53ql9
ping -c 3 dojo-8lw53ql9
ssh root@prod-8lw53ql9

https://prod-8lw53ql9.lab.practical-devsecops.training/
admin	admin
https://dojo-8lw53ql9.lab.practical-devsecops.training/login?next=/
root	pdso-training

ssh prod-8lw53ql9
systemctl start nginx


--Linux Commands--
ls
ls -l
mkdir my-directory
rmdir my-directory
pip3 install ansible==8.7.0 ansible-lint==4.3.7
pip3 install ansible==8.7.0 ansible-lint==4.3.7 &


--Files and Directories--
pwd
nano myfile
cat myfile
mv myfile newfile
rm newfile


--Command Outputs--
cat /etc/passwd > mypasswd.txt
cat mypasswd.txt
cat /etc/passwd >> mypasswd.txt
echo "this is a string"
echo $HOSTNAME
echo "this is a string" > file.txt
cat mypasswd.txt | cut -d ':' -f 1
ps -aux | grep bash


--File Permissions--
ls -l myfile
stat myfile
chmod +x myfile
./myfile
sudo ls
echo -e "pdevsecops\npdevsecops" | adduser --gecos "" john
usermod -aG sudo john
sudo su - john
echo pdevsecops | sudo -S cat /etc/shadow
exit

--Linux Exit Code--
ls non-existent-dir
echo $?
touch newfile
echo $?

cat > myfaketool << EOL
#!/bin/bash
vulncount=\$((0 + \$RANDOM % 3)); #randomly fake vulnerability count
if [ \$vulncount -eq 0 ];
then
        echo "No Vulnerabilities";
        exit 0
else
        echo "Vulnerabilities found: \$vulncount";
        exit 99
fi
EOL

chmod +x myfaketool
./myfaketool
echo $?


--Git--
#	root	pdso-training
git config --global user.email "student@pdevsecops.com"
git config --global user.name "student"
git clone git@gitlab-ce-8lw53ql9:root/django-nv.git
cd django-nv

cat > myfile <<EOL
This is my file
EOL

echo "Practical DevSecOps" >> README.md
git status
git add myfile README.md
git commit -m "Add myfile and update README.md"
git push
git pull

git branch new-branch
git branch --list
git branch --show-current
git checkout new-branch
git checkout -b checkout-branch
git switch -c switch-branch
echo "I am ready to be awesome with Practical DevSecOps" >> README.md
git add README.md
git commit -m "update the new text to README.md"
git push origin new-branch

git branch --list
git checkout main
git pull origin main
git branch -D new-branch


--SSH--
ssh -i ~/.ssh/id_rsa root@prod-8lw53ql9
ssh-keyscan -t rsa prod-8lw53ql9 >> ~/.ssh/known_hosts
hostname
ssh root@prod-8lw53ql9 "hostname"

cat >> /etc/ssh/sshd_config <<EOF
RSAAuthentication yes
PubKeyAuthentication yes
EOF

service sshd restart
ssh-keygen -t rsa
ssh-copy-id -i ~/.ssh/id_rsa.pub user@targetserver

sshd	Server needs to be configured to allow ssh
ssh-keygen	Generates a new public-private key pair for authentication
private key	Never shared with anyone, it is only used during authentication
public key	Needs to be exported to ~/.ssh/authorized_keys on a server to which we need to connect to
ssh-copy-id	Helps in copying public keys to the authorized_keys file


--jq--
jq --help
echo '{"cloudprovider":{"name":"AWS","url":"www.aws.com"}} ' | jq '.'
curl https://randomuser.me/api/
curl https://randomuser.me/api/ | jq '.'

cat > learnjq.json << EOL
[{"details":{"name": "AWS","url": "www.amazon.com"},"services": [{"type": "CI-CD","name": "AWS CodeBuild"},{"type": "Secret management","name": "AWS Secrets Manager"}]},{"details": {"name": "Azure","url": "www.azure.com"},"services": [{"type": "CI-CD","name": "Azure DevOps"},{"type": "Secret management","name": "Azure Key Vault"}]},{"details": {"name": "GCP","url": "www.cloud.google.com"},"services": [{"type": "CI-CD","name": "Cloud Build"},{"type": "Secret management","name": "Secret Manager"}]}]
EOL

cat learnjq.json
jq '.' learnjq.json
jq '.[] |  .details' learnjq.json
jq '.[] | {name: .details.name, url:.details.url}' learnjq.json
jq '.[1] | {name: .details.name, url: .details.url}' learnjq.json
jq '[.[] | {name: .details.name, url: .details.url}]' learnjq.json
jq '.[] | {name: .details.name, url: .details.url, services: .services[]}' learnjq.json
jq '.[] | {name: .details.name, url: .details.url, services: [.services[]]}' learnjq.json
jq '.[] | {name: .details.name, url: .details.url, services: .services}' learnjq.json
jq '.[] | {name: .details.name, servicecount: .services | length}' learnjq.json
jq '.[] | select(.details.name=="AWS")' learnjq.json
jq '.[] | select(.services[].type=="CI-CD") | .details.name' learnjq.json
jq '.[].services[] | select(.type=="CI-CD")' learnjq.json
jq '.[].services[] | select(.type=="CI-CD") | .name' learnjq.json


--vi--
vi security-report.json
/High
v - visual mode
shift+v - visual line mode (d to delete line)


--nano--
nano security-report.json


--Host files using HTTP server--
python3 -m http.server &


--Docker Command--
docker pull ubuntu
docker pull -q alpine
docker run -d --name myubuntu ubuntu
docker ps
docker run -d --name myubuntu -i ubuntu
docker rm myubuntu
docker run -d --name myubuntu -i ubuntu
docker ps
docker run busybox
docker run -d -i busybox
docker ps

docker stop myubuntu
docker start myubuntu

docker exec myubuntu whoami
docker exec myubuntu cat /etc/lsb-release
docker exec -it myubuntu bash

docker run -d --name yourubuntu ubuntu
docker ps -a
docker top myubuntu

docker run -d nginx:1.21.3
docker run -d --name webserver --env APP=nginx nginx:1.21.3
docker run -d --name webserver -e APP=nginx nginx:1.21.3
docker stop webserver && docker rm webserver
docker run -d --name=webserver --env APP=nginx -p 80:80 nginx:1.21.3


--Docker Image--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv.git
cat Dockerfile

FROM	Initialize an operating system that will be used as a base
COPY	Copy files or directories from the host to the container
WORKDIR	Sets the working directory similar to cd command on Linux
RUN		Execute commands in the current image

docker build -t django.nv:1.0 .
docker images

docker tag django.nv:1.0 django.nv:1.1
docker run --name webserver -it --entrypoint /bin/bash django.nv:1.0
docker rmi django.nv:1.0


--Manage Data in Docker--
*Docker Volumes*
docker volume --help
docker volume ls
docker volume create demo
ls /var/lib/docker/volumes/
docker run --name ubuntu -d -v demo:/opt -it ubuntu:20.04
docker exec -it ubuntu bash
echo "Welcome to the containers" > /opt/welcome.txt
docker rm -f ubuntu
ls /var/lib/docker/volumes/demo/_data/
docker run --name ubuntu1 -d -v demo:/tmp -it ubuntu:20.04
docker exec -it ubuntu1 ls /tmp

*Blind Mounts*
docker run --name ubuntu2 -d -v /opt:/opt -it ubuntu:20.04
docker exec -it ubuntu2 bash
ls /opt
ls /var/lib/docker/volumes
ls /opt
echo "Hello from the host" > /opt/welcome.txt
docker rm -f ubuntu2
docker run --name ubuntu2 -d -v /opt:/opt -it ubuntu:20.04
docker exec -it ubuntu2 bash
ls /opt
#This tmpfs mount will not save the data persistently as it uses host’s memory(RAM) as a temporary storage.
docker run --name bindmount -v /opt/hello.txt:/src/hello.txt ubuntu:20.04
docker run --name volumemount -v data:/src ubuntu:20.04 "/bin/bash" "-c" "echo test>>/src/hello.txt"


--Docker Registry--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv
FROM	Initialize an operating system as a base (image)
COPY	Copy the files or directories from the host to the container
WORKDIR	Sets the working directory in the container. Similar to the cd command on Linux
RUN	Executes the commands in the current image

docker build -t django.nv:1.0 .
docker images
docker run -d -p 5000:5000 --restart=always --name registry registry:2
REGISTRY_URL/IMAGE_NAME:IMAGE_TAG
docker tag django.nv:1.0 localhost:5000/django.nv:1.0
docker push localhost:5000/django.nv:1.0
curl localhost:5000/v2/_catalog

docker login -u your-docker-username -p your-docker-password
docker login
docker tag django.nv:1.0 dockerhubusername/django.nv:1.0
docker push dockerhubusername/django.nv:1.0
docker stop registry
docker rmi django.nv:1.0


--Docker Netowrking--
bridge	This is the default network driver when you don’t specify a driver for the containers. Containers on the same bridged network can speak to each other, but are isolated from containers on other bridged networks. All containers can access the external network through NAT
host	The containers use the host’s networking directly, while retaining separation on storage and processing. Ports exposed by the container are exposed on the external network using the host’s IP address
macvlan	When creating a macvlan, you assign a parent network device (e.g. “eth0”). Each container on the macvlan network will receive its own MAC address on the network that eth0 is connected to. Each container has full network access. Warning: when misconfigured, you may overrun the network with too many MACs, or you may duplicate IP addresses
none	networking is disabled with this network driver, containers cannot communicate to each other, nor with the external network

*Bridge*
docker network --help
docker network ls
docker network list
docker network create mynetwork
docker inspect mynetwork
docker run -d --name ubuntu --network mynetwork -it ubuntu:20.04
docker exec ubuntu apt update
docker rm -f ubuntu
docker network rm mynetwork

*macvlan*
docker network create --driver macvlan mymacvlan
ifconfig
docker run -d --name ubuntu --network mymacvlan -it ubuntu:20.04
docker inspect ubuntu -f "{{json .NetworkSettings.Networks }}" | jq
docker rm -f ubuntu
docker network rm mymacvlan

*none*
docker run -d --name ubuntu --network=none -it ubuntu:20.04
docker inspect ubuntu -f "{{json .NetworkSettings.Networks }}" | jq
docker exec ubuntu apt update

docker network create --help
docker network create app --subnet "172.10.2.0/16"
docker run -d -it --name myubuntu ubuntu:20.04
docker network connect app myubuntu
docker network rm app
docker stop myubuntu && docker network rm app


--Dockerfile--
FROM	Creates a layer from Docker Image. Specifies the base image to use
COPY	Copies the files from the local directory to the docker image on a specific location
ADD	Similar to COPY but supports file download (HTTP), auto extracting compressed file(s), and replacing the existing file to a specific location if needed forcefully
RUN	Run OS command (just like you would do on a terminal) but only executes it during the image creation process
ENTRYPOINT	Run a command as the default command when the container starts. Its the entrypoint to the utility/command
CMD	Command to run when a container starts or arguments to ENTRYPOINT if specified

mkdir learn-dockerfile
touch Dockerfile

cat > Dockerfile <<EOL
FROM ubuntu:20.04

RUN apt update && apt install nginx -y

CMD ["/bin/bash", "-c" , "service nginx start; sleep infinity"]
EOL

#if multiple CMD commands, only last one runs

docker build -t nginx-custom .
docker images
docker run -d --name ubuntu -it ubuntu:20.04
docker exec -it ubuntu bash
apt update
apt install -y nginx
service nginx start
apt install curl -y
docker build -t custom-nginx .
docker run -d -it --name custom-nginx-container custom-nginx
docker ps -a
docker logs custom-nginx-container
docker build -t custom-nginx .
docker rm -f custom-nginx-container
docker run -d -it --name custom-nginx-container custom-nginx

cat > Dockerfile <<EOL
FROM ubuntu:20.04

RUN apt update && apt install nginx -y

ENTRYPOINT ["/bin/bash", "-c"]

CMD ["service nginx start"]
EOL

#Please have a look at docker logs command, the CMD instruction is successfully run or completed the job but, since there is no other process that keeps the container alive it causes the container to exit.
docker run -d --name nginx-one -it custom-nginx bash
#We override the CMD instruction to run bash shell instead of service nginx start to interact with the container. The CMD is overridden from the Docker Command Line Interface (CLI) when running the container using docker run command.


--Optional: Working with Grep--
#Grep is a command-line utility in Unix and Linux used for searching and filtering text. Grep stands for “global regular expression print”. It searches text patterns within files. You supply it with a list of files (or input stream), a pattern (or regular expression), and it will print out every line that matches the pattern.

#-v			Invert match: Selects all lines not containing the specified pattern.
#-i			Ignore case: Ignores case distinctions in both the pattern and the input files.
#-r or -R	Recurse: Reads all files under each directory, recursively.
#-l			Only the names of files containing the pattern are listed, not the lines containing the occurrences.
#-c			Suppresses normal output and gives the count of lines matching the pattern for each input file.

grep [options] pattern [filename]

#grep		The command used to search for a pattern in files.
#[options]	Optional flags that control the behavior of grep.
#pattern		The text or regular expression you are searching for.
#[file…]		The file or files where the search will take place.

echo "I love learning DevSecOps in a super way." | grep "DevSecOps"

cat > file1.txt<<EOF
We love DevSecOps because it integrates security practices within the DevOps process. DevSecOps involves introducing security earlier into the lifecycle of application development—rather than being the last stage in development cycles. This method drastically minimizes vulnerabilities and brings security closer to IT and business objectives. DevSecOps enhances collaboration and opens up a fast, more secure delivery ecosystem. It allows for speedier delivery with significantly less risk, providing a framework for a more secure software development process. Embracing a DevSecOps approach ensures a cultural shift, where every stakeholder in the project takes ownership of security, leading to safer and more secure code deployments.
EOF

grep "DevSecOps" file1.txt
grep "DevSecOps involves introducing security earlier into the lifecycle of application development—rather than being the last stage in development cycles" file1.txt

#JSON files
grep "Actor" json-folder/*
grep -r "Actor" json-folder/
grep -c "Actor" json-folder/*
grep -v "Actor" json-folder/file1.json

#-A	The -A flag followed by a number (grep -A) instructs grep to display not only the line that matches the specified text but also the specified number of lines after. For example, grep -A5 “Line5” sample.txt displays the line containing “Line5” and the next 5 lines after the match.
#-B	The -B flag followed by a number (grep -B) directs grep to display the matching line and the specified number of lines before it. For instance, grep -B3 “Line7” sample.txt displays the line containing “Line7” and the preceding 3 lines.
#-C	The -C flag (or --context) followed by a number (grep -C) instructs grep to print the matching line and the specified number of lines both before and after it, providing context. For example, grep -C2 “Line6” sample.txt displays the line containing “Line6” and 2 lines before and after it.

echo -e "Line1\nLine2\nLine3\nLine4\nLine5\nLine6\nLine7\nLine8\nLine9\nLine10" > line.txt
grep -A5 "Line2" line.txt
grep -B3 "Line10" line.txt
grep -C2 "Line5" line.txt

docker --help | grep "images"
#Since docker contains uppercase characters, let’s ignore case sensitivity by using the -i flag.
docker --help | grep -i "docker"


--Optional: Working with Awk--
cat > names.txt <<EOF
Kurt Donald Cobain
James Douglas Morrison
John Winston Lennon
EOF

awk '{print $1}' names.txt
awk '{print $2}' names.txt
awk '{print $2, $3}' names.txt
awk '$2 == "Douglas" {print $0}' names.txt

cat /etc/passwd
cat /etc/passwd | awk -F: '{print $1}'
cat /etc/passwd | awk -F: '{print $1, $6}'

cat > scores.txt <<EOF
Kurt 85
Jimmy 100
Lennon 92
EOF

awk '{ sum += $2; } END { print "Total Score:", sum; }' scores.txt


--Optional: Working with Sed--
cat>myfile.txt<<EOF
apple 
banana
grapefruit
apple
EOF

sed -n '1p' myfile.txt
sed -i '1d' myfile.txt
cat myfile.txt
sed 's/banana/mango/g' myfile.txt

cat >> myfile.txt <<EOF
error error error
EOF

cat myfile.txt
sed '/error/d' myfile.txt


--Optional: Learn the Basics Find--
mkdir -p /home/user/documents
touch /home/user/documents/file1.txt
touch /home/user/documents/file2.txt
touch /home/user/documents/important.txt
touch /home/user/documents/document.doc

find /home/user/documents -name "*.txt"
find /home/user/documents -type d
find /home/user/documents -size +1M
find /home/user/documents -name "*.txt" -delete


--Optional: Create a Snapshot in Docker--
docker run -d --name ubuntu -i ubuntu:20.04
docker exec -it ubuntu bash
apt update && apt install -y nginx
exit

#Instead of creating the Dockerfile, we can run a container and execute the command directly to create the image.
#docker save command only works with the image, it can’t create a snapshot from the container.
docker save ubuntu > ubuntu-save.tar
docker export ubuntu > ubuntu-export.tar
ls -l --block-size=M

#The size is 2x more than docker save command. why? save only saves the image layers, history and deleted/overridden files. It doesn’t save the current state of container even after we executed the command like apt update and also installed the package. This should have also increased the size of image but it did not increase the size when using docker save.

docker load -i ubuntu-save.tar
docker import ubuntu-export.tar ubuntu-export
docker images

#ubuntu-export saves our last state when we installed nginx, lets check it.
docker run -d --name ubuntu -i ubuntu-export

#We got an error when we try to run this image, lets check the history of image.
docker history ubuntu-export

#Based on the above result, we now know that if we use export then it doesn’t save USER, EXPOSE, RUN and other syntax that we used when creating Dockerfile. If you notice it only has one layer.
#Where as docker export flattens the image, used on running containers. It doesn’t save the volume. You will have to save it separately if that’s of interest to you.
#docker save is used on images. It stores layers and other metadata from docker images.


--Optional: Docker Compose--
#This tool allows us to handle multiple containers using a single file called docker-compose.yml.
docker run -d --name ubuntu -i ubuntu:20.04

cat >docker-compose.yml<<EOF
version: "3"

services:
  ubuntu:
    image: ubuntu:20.04
    container_name: ubuntu1
    stdin_open: true        # the same way like docker run -i
EOF

docker-compose up -d
docker ps

docker rm -f $(docker ps -aq)
docker-compose down

#version			Version of compose file format to use, check out this link
#image				Specify the image to run
#container_name		Specify a custom container name, rather than a default name
#ports				Expose port(s), similar to docker run -p argument
#environment		Add environment variables into the container by defining a key-value pair
#volumes			Volumes to save our data persistently using various options type like bind or volumes

cat >~/docker-compose.yml<<EOF
version: "3"

services:
  ubuntu:
    image: ubuntu:20.04
    container_name: myubuntu
    volumes:
     - data:/opt

  alpine:
    image: alpine:3.13
    container_name: myalpine
    volumes:
     - data:/tmp

volumes:
  data:
EOF

cd ~/
docker-compose up -d
docker-compose ps

#Why these two containers have stopped (exited (0))? Because there is no main process running inside the container, we can make the containers running by adding a process like shell or sleep command.
docker-compose down

#Create a compose file at /opt/docker-compose.yml with the service and container named webserver using the nginx image (without a specific version). Bind port 80 from the container to port 8080 on the host. Ensure that the container is running and not exited
cat > /opt/docker-compose.yml<<EOF
version: "3"
services:
  webserver:
    image: nginx
    container_name: webserver
    ports:
     - 8080:80
EOF

#Add docker volume name data into webserver service and mapping it to /usr/share/nginx/html
cat > /opt/docker-compose.yml<<EOF
version: "3"
services:
  webserver:
    image: nginx
    container_name: webserver
    ports:
     - 8080:80
    volumes:
     - data:/usr/share/nginx/html

volumes:
  data:
EOF

#Create a random file with hello world text inside the webserver container and save it in /usr/share/nginx/html/hello.html
#The docker-compose.yml file is located at the /opt directory. So we can either cd in to the /opt directory, and then run docker-compose up -d or use the below command to run docker-compose with a docker-compose.yml file in another location.
docker-compose -f /opt/docker-compose.yml up -d
docker exec webserver sh -c 'echo "hello world" > /usr/share/nginx/html/hello.html'
#OR
docker-compose exec webserver sh -c 'echo "hello world" > /usr/share/nginx/html/hello.html'




----Secure SDLC and CI/CD Pipeline----
#Maturity Model (DSOMM)
#Dynamic Depth - How deep dynamics scans are
#Static Depth - How deep static code analysis
#Intensity - How intense is majority of executed attacks
#Consolidation - How complete process of handling findings
#DSOMM Level 1 - Run SAST and DAST with default settings
#DSOMM Level 2 - Run SAST and DAST minor tweaks
#Level 3 and 4 in Advanced Course


--GitLab CI/CD--
# This is how a comment is added to a YAML file; please read them carefully.

stages:         # Dictionary
 - build        # this is build stage
 - test         # this is test stage
 - integration  # this is an integration stage
 - staging      # this is a staging stage
 - prod         # this is prod/production stage

job1:
  stage: build  # this job belongs to the build stage.
  script:
    - echo "This is a build step."  # We are running an echo command, but it can be any command.

job2:
  stage: test
  script:
    - echo "This is a test step."
    - exit 1          # Non zero exit code, fails a job.

job3:          
  stage: integration  # integration stage
  script:
    - echo "This is an integration step."

job4:
  stage: staging
  script:
    - echo "This is a staging step."

job5:
  stage: prod
  script:
    - echo "This is a deploy step."
	

--Stages in GitLab CI/CD--
#Build: This is where the initial code compilation happens, getting it ready for further testing.
#Test: In this stage, the software undergoes thorough testing to find and fix any issues, ensuring its quality.
#Integration: Here, the software is combined with other systems to check that it works well within the larger setup.
#Deploy: The last stage, where the software is released to production settings, becoming accessible to users.

django_deployment:
  stage: deploy
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery

--Artifacts in GitLab--
stages:   # Dictionary
 - build   # this is build stage
 - test    # this is test stage
 - integration # this is an integration stage
 - prod       # this is prod/production stage

build:       # this is job named build, it can be anything, job1, job2, etc.,
  stage: build    # this job belongs to the build stage. Here both job name and stage name is the same i.e., build
  script:
    - echo "This is a build step"  # We are running an echo command, but it can be any command.
    - echo "{\"vulnerability\":\"SQL Injection\"}" > vulnerabilities.json
  artifacts:      # notice a new tag artifacts
    paths: [vulnerabilities.json]   # this is the path to the vulnerabilities.json file
    when: always
    expire_in: 1 week       # <--- To save disk space, we want to store only for 1 week

test:
  stage: test
  script:
    - echo "This is a test step."
    - exit 1         # Non zero exit code, fails a job.
  allow_failure: true   #<--- allow the build to fail but don't mark it as such

integration:        # integration job under stage integration.
  stage: integration
  script:
    - echo "This is an integration step."

prod:
  stage: prod
  script:
    - echo "This is a deploy step."


stages:   # Dictionary
 - build   # this is build stage
 - test    # this is test stage
 - integration # this is an integration stage
 - prod       # this is prod/production stage

build:       # this is job named build, it can be anything, job1, job2, etc.,
  stage: build    # this job belongs to the build stage. Here both job name and stage name is the same i.e., build
  script:
    - echo "This is a build step"  # We are running an echo command, but it can be any command.

test:
  stage: test
  script:
    - echo "This is a test step."
    - docker run -i -v $(pwd):/app alpine sh -c "echo '{\"vulnerability\":\"XSS Injection\"}' > /app/vulnerabilities.json" # make an output file created in /app path
  artifacts:      # notice a new tag artifacts
    paths: [vulnerabilities.json]   # this is the path to the vulnerabilities.json file in the local CI/CD machine
  allow_failure: true   #<--- allow the build to fail but don't mark it as such

integration:        # integration job under stage integration.
  stage: integration
  script:
    - echo "This is an integration step."

prod:
  stage: prod
  script:
    - echo "This is a deploy step."

#Docker has a -v command to bind the local machine path to the Docker container machine path. Please refer to the Manage data in Docker exercise for a detailed explanation.
#https://stackoverflow.com/questions/36053968/mount-volume-to-host


--Advanced GitLab CI/CD--
- exit 1	# Non zero exit code, fails a job.
test:
  stage: test
  script:
     - execute_script_that_will_fail
  allow_failure: true   #<--- allow the build to fail but don't mark it as such
 
someScan:
  script: ./security-tool.sh    # <-- this tool generates vulnerabilities.json as output
  artifacts:                    # <--- To save results, we use artifacts tag
    paths:                      # <--- We then give the path/paths of the scan result files we want to store for further processing
    - vulnerabilities.json                  #<--- The filename
    expire_in: 1 week       # <--- To save disk space, we want to store only for 1 week

deploy_prod:
  stage: deploy
  script:
    - echo "Deploy to prod server."
  when: manual   #<-- A human has to click a button (play button in Gitlab) for this task to execute.


stages:   # Dictionary
 - build   # this is build stage
 - test    # this is test stage
 - integration # this is an integration stage
 - prod       # this is prod/production stage

build:       # this is job named build, it can be anything, job1, job2, etc.,
  stage: build    # this job belongs to the build stage. Here both job name and stage name is the same i.e., build
  script:
    - echo "This is a build step"  # We are running an echo command, but it can be any command.
    - echo "{\"vulnerability\":\"SQL Injection\"}" > vulnerabilities.json
  artifacts:      # notice a new tag artifacts
    paths: [vulnerabilities.json]   # this is the path to the vulnerabilities.json file

test:
  stage: test
  script:
    - echo "This is a test step."
    - exit 1         # Non zero exit code, fails a job.
  allow_failure: true   #<--- allow the build to fail but don't mark it as such

integration:        # integration job under stage integration.
  stage: integration
  script:
    - echo "This is an integration step."

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual   #<-- A human has to click a button (play button in Gitlab) for this task to


stages:   # Dictionary
 - build   # this is build stage
 - test    # this is test stage
 - integration # this is an integration stage
 - deploy       # this is prod/production stage

integration:
    stage: integration
    script:
        - echo "this is an output" > output.txt
        - exit 1
    artifacts:
        paths: [output.txt]
        when: always
    allow_failure: true

deploy:
    stage: deploy
    when: manual


--How CI/CD Works--
#Set up environment
Running with gitlab-runner 16.4.0 (4e724e03)
  on gitlab-runner-77k0huze BxQ1DEzn, system ID: s_93fa9ab39c75
Preparing the "docker" executor 00:43
Using Docker executor with image docker:20.10 ...
Using helper image:  gitlab/gitlab-runner-helper:x86_64-latest  (overridden, default would be  registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-4e724e03 )
Pulling docker image gitlab/gitlab-runner-helper:x86_64-latest ...

...[SNIP]...

#Get sources from git repo
$ rm -f .git/index.lock
Fetching changes with git depth set to 20...
Initialized empty Git repository in /builds/BxQ1DEzn/0/root/django-nv/.git/
Created fresh repository.
Checking out 8ee7dc23 as detached HEAD (ref is main)...
Skipping Git submodules setup

...[SNIP]...

#Execute YAML file
image: docker:20.10

services:
  - docker:dind

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

job:
  stage: build
  script:
    - echo "I'm a job"
    - whoami
    - hostname 
	- cat /proc/self/mountinfo

...[SNIP]...

#End result
Executing "step_script" stage of the job script 00:01
Using docker image sha256:ed9a10a5bc310dfdad94ab737c61698d5a5bc8074a039804531452fe19200896 for docker:20.10 with digest docker@sha256:2967f0819c84dd589ed0a023b9d25dcfe7a3c123d5bf784ffbb77edf55335f0c ...
$ echo "I'm a job"
I'm a job
Job succeeded

*Docker-in-Docker*
image: docker:20.10

services:
  - docker:dind

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

job1:
  stage: build
  script:
    - docker version
    - docker run --rm -v $(pwd):/src hysnsec/safety check -r /src/requirements.txt --json

#docker run	This command is used to run a Docker container.
#--rm	This flag stands for remove and is used to automatically remove the container after it finishes running. This helps in keeping your system clean by removing temporary containers.
#-v $(pwd):/src	This option sets up a volume mount within the container. It binds the current working directory to the /src directory inside the container.
#hysnsec/safety	This refers to the Docker image you want to run. In this case, it is the image named hysnsec/safety, which contains the Safety tool.
#check -r /src/requirements.txt –json	These are the arguments passed to the safety check command within the container. It instructs the Safety tool to check the Python packages specified in the requirements.txt file located inside the /src directory. The –json flag tells Safety to output the results in JSON format.

#The above single line of code scans the requirements.txt file for vulnerabilities without the need to install the safety tool using the pip3 install command.
#The purpose is the same as the code snippet below.
job1:
  stage: build
  image: python:3.6
  script:
    - pip install safety
    - safety check -r /src/requirements.txt --json


--GitLab Rules for Conditional Pipelines--
#rules is YAML syntax for GitLab CI to include or exclude your jobs in pipelines. rules replaces the only and except clauses. Using this syntax, you can control when a job will be triggered in a pipeline based on the rules you defined in .gitlab-ci.yml file.
rules:if
#(==, !=, =~, ~=) and conjunction/disjunction like (&&, ||)
rules:changes
#The job named build should only run when a file named Dockerfile is changed
rules:exists
#A job will run when certain file exists
rules:allow_failure

stages:         # Dictionary
 - build        # this is build stage
 - test         # this is test stage
 - integration  # this is an integration stage
 - prod         # this is prod/production stage

build:              # this is job named build, it can be anything, job1, job2, etc.,
  stage: build      # this job belongs to the build stage. Here both job name and stage name is the same, i.e., build
  script:
    - echo "This is a build step."          # We are running an echo command, but it can be any command.
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - Dockerfile

job4:
  stage: staging
  script:
    - echo "This is a deploy step to staging environment."
    - exit 1    # Non zero exit code, fails a job.
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'   # this job will get triggered when the branch name is __main__
      allow_failure: true

job5:
  stage: prod
  script:
    - echo "This is a deploy step to production environment."
  rules:
    - if: '$CI_COMMIT_TAG !~ "/^$/"'   # this job will trigger when you create a new tag
      when: manual


--Continuous Deployment Using GitLab--
*Simple CI/CD Pipeline
#View ID_RSA
more /root/.ssh/id_rsa

#YAML with Complete Code
image: docker:20.10

services:
  - docker:dind

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py check

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

release:
  stage: release
  before_script:
   - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY
  script:
   - docker build -t $CI_REGISTRY_IMAGE .  # Build the application into Docker image
   - docker push $CI_REGISTRY_IMAGE        # Push the image into registry

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  image: kroniak/ssh-client:3.6
  environment: production
  only:
      - main
  before_script:
   - mkdir -p ~/.ssh
   - echo "$PROD_SSH_PRIVKEY" > ~/.ssh/id_rsa
   - chmod 600 ~/.ssh/id_rsa
   - eval "$(ssh-agent -s)"
   - ssh-add ~/.ssh/id_rsa
   - ssh-keyscan -t rsa $PROD_HOSTNAME >> ~/.ssh/known_hosts
  script:
   - echo
   - |
      ssh $PROD_USERNAME@$PROD_HOSTNAME << EOF
        docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
        docker rm -f django.nv
        docker run -d --name django.nv -p 8000:8000 $CI_REGISTRY_IMAGE
      EOF


--Integrate Tool Into CI/CD--
*ZAP (Zed Attack Proxy)*
docker pull ghcr.io/zaproxy/zaproxy:stable

#Run the Docker container on your local machine using the terminal
docker run -v $(pwd):/zap/wrk/:rw -t ghcr.io/zaproxy/zaproxy:stable zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training -r testreport.html

#Starts an instance of the Docker container hosting ZAP and launches the zap-baseline.py script within the container
#The --user $(id -u):$(id -g) option specifies the user and group IDs within the container, ensuring they match the user initiating the command on the host which aids in averting potential permission issues in the writing of files to mounted volumes.
docker run --user $(id -u):$(id -g) -v $(pwd):/zap/wrk/:rw -t ghcr.io/zaproxy/zaproxy:stable zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training -r testreport.html

*hysnsec/safety*
docker pull hysnsec/safety

#This command starts an instance of the Docker container running hysnsec/safety. Notably, the –rm option prompts Docker to automatically clean up the container after it exits, and -v $(pwd):/src mounts the current directory on the host to /src in the container.
docker run --rm -v $(pwd):/src hysnsec/safety check

#If you need to save the output data from hysnsec/safety for further analysis or reporting, you can append an output redirection operator (>) at the end of the command followed by the output file’s name. The expanded command looks like this:
#In this case, the --json option is used to specify the output format. Here, hysnsec/safety will provide a JSON-formatted output. The output will be redirected into a file named testreport.json. Since the file is located within the shared volume /src (which corresponds to the current directory $(pwd) on the host), it will be accessible from outside the container even after the container has been removed. This practice allows data persistence beyond the lifecycle of the Docker container and is highly useful for further data analysis or for integrating into a pipeline.
docker run --rm -v $(pwd):/src hysnsec/safety check --json > testreport.json

*Docker Run Commands and Output Redirects*
#JSON saved inside container
docker run --rm -v $(pwd):/project image_name sh -c "command --json > output.json"

#JSON saved to host machine
docker run --rm -v $(pwd):/project image_name sh -c "command --json" > output.json

#Understanding and modifying docker run commands is crucial, 
#Pay attention to the order and placement of arguments, options
#Be aware of the options available for volume mappings, working directory configurations, and output redirects
#Always refer to the documentation of the specific tool or command you are running inside the Docker container


--Optional: Pipeline as Code (PaC) using Jenkins--
#In jenkins create Pipeline
#Next, click on the Build Triggers tab, check the Build when a change is pushed to GitLab checkbox.
#At the bottom right-hand side, choose the Advanced button below the Comment (regex) for triggering a build form field.
#Click on the Generate button under Secret token to generate a token.
2d1897d18e250b39ffb16945778caaac
#We will use this token for GitLab’s Webhook Settings. This webhook setting will allow GitLab to let Jenkins know whenever a change is made to the repository.
#Add a new webhook in GitLab
#Completing the job configuration - Click on the Pipeline tab, and select Pipeline script from SCM from Definition options. Once you do that, few more options would be made available to you.
#Select Git as SCM, enter our django.nv repository http url.
#In branches to build, change Branch Specifier option from */master to */main.

#There are two ways to write Pipeline as Code in Jenkins:
#Declatarive Pipeline
#Scripted Pipeline

#For your reference, a simple Declarative pipeline is shown below.
pipeline {
    agent any
    stages {
        stage('build'){         // similar to __stage__ in .gitlab-ci.yml
            steps{              // similar to __script__ in .gitlab-ci.yml
                echo "hello"
            }
        }
    }
}
#In Jenkinsfile, we don’t need to define stages at the beginning of the file, like we used to do in Gitlab.
#We define a stage inside the stages as shown below.

pipeline {
    agent any

    stages {
        stage("build") {
            steps {
                echo "This is a build step"
            }
        }
        stage("test") {
            steps {
                echo "This is a test step"
            }
        }
        stage("integration") {
            steps {
                // Allow the stage to fail
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step"
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
    }
}


--Optional: Continuous Integration using Jenkins--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build and test") {
            parallel {
                stage("build") {
                    agent {
                        docker {
                            image 'python:3.6'
                            args '-u root'
                        }
                    }
                    steps {
                        sh """
                        pip3 install --user virtualenv
                        python3 -m virtualenv env
                           . env/bin/activate
                        pip3 install -r requirements.txt
                        python3 manage.py check
                        """
                    }
                }
                stage("test") {
                    agent {
                        docker {
                            image 'python:3.6'
                            args '-u root'
                        }
                    }
                    steps {
                        sh """
                        pip3 install --user virtualenv
                        python3 -m virtualenv env
                        . env/bin/activate
                        pip3 install -r requirements.txt
                        python3 manage.py test taskManager
                        """
                    }
                }
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step"
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step"
            }
        }
        stage("artifact") {
            steps {
                script {
                    // Create a simple text file using the echo command
                    sh 'echo "This is an artifact file" > artifact.txt'

                    // Archive the artifact file
                    archiveArtifacts artifacts: 'artifact.txt'
                }
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'canceled')
        }
        always { 
            deleteDir()                     // clean up workspace
        }
    }
}


--Optional: Continuous Deployment using Jenkins--
cat > Jenkinsfile <<EOL
#!/usr/bin/env groovy
pipeline {
    agent any
    environment {
        registryUrl = "gitlab-registry-8lw53ql9.lab.practical-devsecops.training"
        registryCreds = "registry-auth"
    }
    options {
        gitLabConnection('gitlab')
    }
    stages {
        stage("build") {
            agent { 
                docker { 
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent { 
                docker { 
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step"
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                sshagent(['ssh-prod']) {
                    sh """
                    ssh -o StrictHostKeyChecking=no root@prod-8lw53ql9 '
                    docker login -u root -p pdso-training $registryUrl
                    docker rm -f django.nv
                    docker pull $registryUrl/root/django-nv:$BUILD_NUMBER
                    docker run -d --name django.nv -p 8000:8000 $registryUrl/root/django-nv:$BUILD_NUMBER
                    '
                    """
                }
            }
        }
    post {
        failure {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'canceled')
        }
        always { 
            deleteDir()                     // clean up workspace
        }
    }
}
EOL

#Next, we will modify prod stage to deploy our application with SSH Agent plugin in Jenkins. This plugin will help you to SSH into the prod machine.
#Lets add our credentials to login into prod machine by visiting https://jenkins-8lw53ql9.lab.practical-devsecops.training/credentials/store/system/domain/_/.
#Click Add Credentials on the left sidebar, and select SSH Username with private key as Kind, then add the following credentials into it.

#ID	            ssh-prod
#Description	  Credentials to login into Production machine
#Username	      root
#Private Key	  Check Enter directly, click the Add button and copy the private key from Production machine, available at /root/.ssh/id_rsa
#Passphrase	    leave it blank because we want this process to be automatic without any human intervention. If you desire more robust credential security, please use dedicated secret management systems like Hashicorp Vault


--Optional: Continuous Integration using GitHub Actions--
#Create a new repository
#Create a Personal Access Token (PAT) - select Read & Write access to Actions,Workflows and Contents.
#Initial git setup
#Download the repository - Let’s start by cloning django.nv in DevSecOps Box.
#Add a workflow file to the repository - create .github/workflows directory and create a new YAML file named demo.yaml
mkdir -p .github/workflows

cat >.github/workflows/demo.yaml<<EOF
name: Django                                  # workflow name

on:
  push:                                       
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                    # similar to "image" in GitLab
    steps:
      - run: echo "This is a build step"      # similar to "script" in GitLab

  test:
    runs-on: ubuntu-20.04
    steps:
      - run: echo "This is a test step"

  integration:
    runs-on: ubuntu-20.04
    steps:
      - run: echo "This is an integration step"
      - run: exit 1

  prod:
    runs-on: ubuntu-20.04
    steps:
      - run: echo "This is a deploy step"
EOF

#Push the changes to the repository
git push origin main


--Optional: Continuous Integration using CircleCI--
#Create a new repository
#Create a Personal Access Token (PAT)
#Initial git setup
#Download the repository - git clone https://gitlab.practical-devsecops.training/pdso/django.nv.git

#Creating an account in CircleCI - To utilize CircleCI, an account must be created by signing up at https://circleci.com/signup
#Please select the Connect option for GitHub.
#Setting Up A New Project In CircleCI

ssh-keygen -t ed25519 -f ~/.ssh/project_key -C <YOUR_GITHUB_EMAIL>
more ~/.ssh/project_key.pub

#Copy your public key as it will be added as a deploy key to GitHub.
#To access the deploy key setup page, navigate to the django.nv repository on GitHub, select Settings, and then go to Deploy Keys within the Security option.
#Next, paste the public key you copied earlier and name your deploy key as CircleCI.
#Make sure to allow write access while setting up the deploy key.

#You need to create .circleci directory and create a new YAML file named config.yml and add the following CI script.
mkdir -p .circleci

cat >.circleci/config.yml<<EOF
jobs:
  build:
    docker:
      - image: python:3.6                   # similar to "image" in GitLab
    steps:
      - checkout
      - run: |                              # similar to "script" in GitLab
          pip install -r requirements.txt
          python manage.py check

  test:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: |
          pip install -r requirements.txt
          python manage.py test taskManager

  integration:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: on_fail      # Even if the job fails, continue to the next jobs

  prod:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "This is a deploy step"

  artifact:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "hello" > hello.txt
      - store_artifacts:
          path: hello.txt
          destination: artifact-file

workflows:
  version: 2
  django:
    jobs:
      - build:
          filters:          # Run the job with a specific branch
            branches:
              only:
                - main
      - test:
          requires:
            - build
          filters:
            branches:
              only:
                - main
      - integration:
          requires:
            - test
          filters:
            branches:
              only:
                - main
      - prod:
          requires:
            - integration
          filters:
            branches:
              only:
                - main
      - artifact:
          requires:
            - prod
          filters:
            branches:
              only:
                - main
EOF

git add .circleci/config.yml
git commit -m "Add CircleCI config"
git push origin main


--Optional: Build a Docker Image in CircleCI--
#Create a new repository
#Create a Personal Access Token (PAT)
git config --global user.email "your_email@gmail.com"
git config --global user.name "your_username"
git clone https://gitlab.practical-devsecops.training/pdso/django.nv.git
cd django.nv
git remote rename origin old-origin
git remote add origin https://github.com/username/django.nv.git
git status
git push -u origin main

#Create CircleCI account and generate ssh key, look at above instructions from previous lab

mkdir -p .circleci

cat >.circleci/config.yml<<EOF
jobs:
  build:
    docker:
      - image: python:3.6                   # similar to "image" in GitLab
    steps:
      - checkout
      - run: |                              # similar to "script" in GitLab
          pip install -r requirements.txt
          python manage.py check

  test:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: |
          pip install -r requirements.txt
          python manage.py test taskManager

  integration:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: always                    # Even if the job fails, continue to the next stages

  prod:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "This is a deploy step."

workflows:
  version: 2
  django:
    jobs:
      - build
      - test:
          requires:
            - build 
      - integration:
          requires:
            - test
      - prod:
          type: approval
          requires:
            - integration
EOF

git add .circleci/config.yml
git commit -m "Add CircleCI config"
git push origin main

#Build Docker Image in CI/CD pipeline
#Click Project Settings on the top right and select Environment Variables to add the following variables in the form of key value pairs.
DOCKER_USERNAME   Your DockerHub username account
DOCKER_PASSWORD   Your DockerHub password account

#Go back to the DevSecOps Box machine, then edit the .circleci/config.yml file using any text editor like nano or vim and copy the following content after the test job.
  release:
    machine: true                                        # What is this for?
    steps:
      - checkout

      - run: |
          docker build -t $DOCKER_USERNAME/django.nv .   # Build the application into Docker image
          docker push $DOCKER_USERNAME/django.nv         # Push the image into registry

#You will notice that the release job failed with the error message denied: requested access to the resource is denied. To fix this, we need to login into the registry with the correct credentials before pushing the image.

#Tip: Don’t hardcode credentials in .circleci/config.yml script.
#You can add the following line to the .circleci/config.yml file before the docker build command.
echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin

git add .circleci/config.yml
git commit -m "Update CI script"
git push origin main




----Software Component Analysis (SCA)----
#A technique to find security vulnerabilities in third party components used in project.
#Sometimes known as Open Source Application Security Testing (OAST)
#PIP - python based packages
#Maven - packages for Java
#NPM - packages for Javascript

#Javascript - Retirejs/npm@6
#Python - Safety
#Ruby on Rails - Bundler audit
#PHP - Composer(limited)
#Java - OWASP Dependency Checker

--Software Component Analysis using Safety--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install safety==2.3.5
safety check --help
safety check -r requirements.txt --json | tee safety-output.json


--Software Component Analysis using RetireJS--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp

#copy all 5 rows below
mkdir -p /etc/apt/keyrings
curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
NODE_MAJOR=20
echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | tee /etc/apt/sources.list.d/nodesource.list
apt update

apt install nodejs -y
npm install -g retire@3.2.3
retire --help
cat package.json
npm install

retire --outputformat json --outputpath retire_output.json
#--outputpath : flag specifies the output file path.
#--outputformat : flag specifies that output format. Here it’s the JSON format.
cat retire_output.json | jq

#Configure retirejs such that it only throws non zero exit code when high severity issues are present in the results
retire --severity high --outputformat json --outputpath retire_output.json

#Mark all high severity issues as False Positive and save the output in JSON format at location /webapp/retire_output.json
cat >/webapp/.retireignore.json<<EOF
[
    {
        "component": "jquery",
        "justification" : "False Positive"
    },
    {
        "component": "qs",
        "version": "0.6.6",
        "justification" : "False Positive"
    },
    {
        "component": "tough-cookie",
        "version": "2.2.2",
        "justification" : "False Positive"
    },
    {
        "component": "handlebars",
        "version": "4.0.5",
        "justification" : "False Positive"
    },
    {
        "component": "growl",
        "version": "1.9.2",
        "justification" : "False Positive"
    },
    {
        "component": "adm-zip",
        "version": "0.4.4",
        "justification" : "False Positive"
    },
    {
        "component":"dojo",
        "version": "1.4.2",
        "justification" : "False Positive"
    },
    {
        "component":"underscore.js",
        "version": "1.8.3",
        "justification" : "False Positive"
    }
]
EOF

retire --severity high --ignorefile .retireignore.json --outputformat json --outputpath retire_output.json
cat retire_output.json | jq '.data[].results[] | select (.vulnerabilities[].severity=="high")' | jq '.component,.version'


--Embed Safety into GitLab--
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

oast:
  stage: test
  script:
    # We are going to pull the hysnsec/safety image to run the safety scanner
    - docker pull hysnsec/safety
    # third party components are stored in requirements.txt for python, so we will scan this particular file with safety.
    - docker run --rm -v $(pwd):/src hysnsec/safety check -r requirements.txt --json > oast-results.json
  artifacts:
    paths: [oast-results.json]
    when: always # What does this do?
  allow_failure: true

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Embed RetireJS into GitLab--
#My YAML file
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

oast-frontend:
	stage: test
	image
	
#Course YAML file
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

oast-frontend:
  stage: test
  image: node:alpine3.10
  script:
    - npm install
    - npm install -g retire # Install retirejs npm package.
    - retire --outputformat json --outputpath retirejs-report.json --severity high
  artifacts:
    paths: [retirejs-report.json]
    when: always # What is this for?
    expire_in: one week
  allow_failure: true

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Fix Issues Reported by SCA--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install safety==2.3.5
safety check --help
safety check -r requirements.txt --json | tee safety-output.json
cat requirements.txt
#Returns Django==3.0, we need to fix this

cat >requirements.txt<<EOF
Django==4.2.9
EOF

safety check -r requirements.txt --json | tee safety-output.json


--Optional: How To Embed Safety Into Jenkins--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            agent { 
                docker { 
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent { 
                docker { 
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("oast") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') { 
                    sh "docker run -v \$(pwd):/src --rm hysnsec/safety check -r requirements.txt --json | tee oast-results.json"
                }
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step."
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'skipped')
        }
        always { 
            archiveArtifacts artifacts: '*.json', fingerprint: true
            deleteDir()                     // clean up workspace
        }
    }
}


--Optional: How To Embed Safety Into GitHub Actions--
name: Django                                  # workflow name

on:
  push:
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04   # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py check

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py test taskManager

  oast:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - uses: actions/checkout@v2

      - run: docker run --rm -v $(pwd):/src hysnsec/safety check -r requirements.txt --json > oast-results.json
        continue-on-error: true             # allow the build to fail, similar to "allow_failure: true" in GitLab

      - uses: actions/upload-artifact@v2
        with:
          name: Safety
          path: oast-results.json
        if: always()                        # what is this for?

  integration:
    runs-on: ubuntu-20.04
    needs: oast
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."


--Optional: How To Embed Safety Into CircleCI--
jobs:
  build:
    docker:
      - image: python:3.6                   # similar to "image" in GitLab
    steps:
      - checkout
      - run: |                              # similar to "script" in GitLab
          pip install -r requirements.txt
          python manage.py check

  test:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: |
          pip install -r requirements.txt
          python manage.py test taskManager

  oast:
    machine: true
    steps:
      - checkout

      - run:
          command: docker run -v $(pwd):/src --rm hysnsec/safety check -r /src/requirements.txt --json | tee oast-results.json || true

      - store_artifacts:
          path: oast-results.json
          destination: safety-artifact
          when: always

  integration:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: on_fail                    # Even if the job fails, continue to the next stages

  prod:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "This is a deploy step"

workflows:
  version: 2
  django:
    jobs:
      - build
      - test:
          requires:
            - build
      - oast:
          requires:
            - test
      - integration:
          requires:
            - oast
      - prod:
          type: approval
          requires:
            - integration


--Optional: Software Component Analysis Using pip-audit--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install pip-audit==1.1.2
pip-audit -r ./requirements.txt -f json | tee pip-audit-output.json


--Optional: How To Embed RetireJS Into Jenkins--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("oast-frontend") {
            agent {
                docker {
                    image 'node:alpine3.10'
                    args '-u root'
                }
            }
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    sh """
                    npm install
                    npm install -g retire
                    retire --outputformat json --outputpath retirejs-report.json --severity high
                    """
                }
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step."
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'skipped')
        }
        always {
            archiveArtifacts artifacts: '*.json', fingerprint: true
            deleteDir()                     // clean up workspace
        }
    }
}


--Optional: How To Embed RetireJS Into GitHub Actions--
mkdir -p .github/workflows

cat >.github/workflows/main.yaml<<EOF
name: Django                                  # workflow name

on:
  push:
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                    # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py check

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py test taskManager

  oast-frontend:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - uses: actions/checkout@v2

      - uses: actions/setup-node@v2
        with:
          node-version: '10.x'

      - run: npm install

      - run: docker run --rm -v $(pwd):/src -w /src hysnsec/retire --outputformat json --outputpath retirejs-report.json --severity high
        continue-on-error: true

      - uses: actions/upload-artifact@v2
        with:
          name: RetireJS
          path: retirejs-report.json
        if: always()                        # what is this for?

  integration:
    runs-on: ubuntu-20.04
    needs: oast-frontend
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."
EOF

git add .github/workflows/main.yaml
git commit -m "Add github workflows"
git push origin main


--Optional: How To Embed RetireJS Into CircleCI--
jobs:
  build:
    docker:
      - image: python:3.6                   # similar to "image" in GitLab
    steps:
      - checkout
      - run: |                              # similar to "script" in GitLab
          pip install -r requirements.txt
          python manage.py check

  test:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: |
          pip install -r requirements.txt
          python manage.py test taskManager

  oast-frontend:
    machine: true
    steps:
      - checkout

      - run:
          command: docker run --rm -v $(pwd):/src -w /src hysnsec/retire --outputformat json --outputpath retirejs-output.json --severity high || true

      - store_artifacts:
          path: retirejs-output.json
          destination: retirejs-artifact
          when: always

  integration:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: on_fail         # Even if the job fails, continue to the next stages

  prod:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "This is a deploy step."

workflows:
  version: 2
  django:
    jobs:
      - build
      - test:
          requires:
            - build
      - oast-frontend:
          requires:
            - test
      - integration:
          requires:
            - oast-frontend
      - prod:
          type: approval
          requires:
            - integration


--Optional: Software Component Analysis Using Dependency-Check--
git clone https://github.com/WebGoat/WebGoat.git webapp
java -h
apt update
apt install openjdk-8-jre -y
wget -O /opt/v8.3.1.zip https://github.com/jeremylong/DependencyCheck/releases/download/v8.3.1/dependency-check-8.3.1-release.zip
unzip /opt/v8.3.1.zip -d /opt/
export PATH=/opt/dependency-check/bin:$PATH
dependency-check.sh -h

dependency-check.sh --scan /webapp --format "JSON" --project "Webgoat" --out /opt
dependency-check.sh --scan /webapp --format "JSON" --project "Webgoat" --failOnCVSS 4 --out /opt

cat >suppression.xml<<EOF
<?xml version="1.0" encoding="UTF-8"?>
<suppressions xmlns="https://jeremylong.github.io/DependencyCheck/dependency-suppression.1.3.xsd">
    <suppress>
        <notes><![CDATA[
        Ignore underscore-min.js issue as FP
        ]]></notes>
        <vulnerabilityName>CVE-2021-23358</vulnerabilityName>
    </suppress>
</suppressions>
EOF

dependency-check.sh --scan /webapp --format "JSON" --project "Webgoat" --failOnCVSS 7 --suppression suppression.xml --out /opt
dependency-check.sh --scan /webapp --format "JSON" --project "Webgoat" --failOnCVSS 7 --out /opt


--Optional: How To Embed Dependency-Check Into GitLab--
git clone https://github.com/WebGoat/WebGoat.git webgoat
cd webgoat
git remote rename origin old-origin
git remote add origin http://gitlab-ce-8lw53ql9.lab.practical-devsecops.training/root/webgoat.git
git push -u origin --all

image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  script:
    - echo "This is a build step"

test:
  stage: test
  script:
    - echo "This is a test step"

odc-backend:
  stage: test
  image: gitlab/dind:latest
  script:
    - chmod +x ./run-depcheck.sh
    - ./run-depcheck.sh
  artifacts:
    paths:
      - reports/dependency-check-report.json
    when: always
    expire_in: one week
  allow_failure: true

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: How To Embed Dependency-Check Into Jenkins--
git clone https://github.com/WebGoat/WebGoat.git webgoat
cd webgoat
git remote rename origin old-origin
git remote add origin http://gitlab-ce-8lw53ql9.lab.practical-devsecops.training/root/webgoat.git
git checkout -b main
git push -u origin main

pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            steps {
                echo "This is a build step"
            }
        }
        stage("test") {
            steps {
                echo "This is a test step"
            }
        }
        stage("odc-backend") {
            agent {
                docker { 
                    image 'docker:20.10-dind'
                    args '-u root -v /var/run/docker.sock:/var/run/docker.sock'
                }
            }
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                sh """
                chmod +x run-depcheck.sh
                ./run-depcheck.sh
                """
            }
            post {
                always {
                    archiveArtifacts artifacts: 'reports/dependency-check-report.json', onlyIfSuccessful: false
                    }
                }
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step."
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus name: STAGE_NAME, state: 'failed'
        }
        unstable {
            updateGitlabCommitStatus name: STAGE_NAME, state: 'failed'
        }
        success {
            updateGitlabCommitStatus name: STAGE_NAME, state: 'success'
        }
        always {
            archiveArtifacts artifacts: '*.json', fingerprint: true
            deleteDir()                     // clean up workspace
            dir("${WORKSPACE}@tmp") {       // clean up tmp directory
                deleteDir()
            }
            dir("${WORKSPACE}@script") {    // clean up script directory
                deleteDir()
            }
        }
    }
}


--Optional: How To Embed Dependency-Check Into GitHub Actions--
cat >.github/workflows/main.yaml<<EOF
name: Webgoat                                 # workflow name

on:
  push:                                       
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04
    steps:
      - run: echo "This is a build step"

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - run: echo "This is a test step"

  odc-backend:
    runs-on: ubuntu-20.04
    name: depecheck_test
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Depcheck
        uses: dependency-check/Dependency-Check_Action@main
        id: Depcheck
        with:
          project: 'webgoat'
          path: '.'
          format: 'JSON'

      - name: Upload Test results
        uses: actions/upload-artifact@master
        with:
           name: Depcheck report
           path: ${{github.workspace}}/reports
EOF


--Optional: How To Embed Dependency-Check Into CircleCI --
cat >.circleci/config.yml<<EOF
jobs:
  build:
    machine: true
    steps:
      - checkout
      - run: echo "This is a build step"

  test:
    machine: true
    steps:
      - checkout
      - run: echo "This is a test step"

  odc-backend:
    machine: true
    steps:
      - checkout

      - run: chmod +x ./run-depcheck.sh && ./run-depcheck.sh

      - store_artifacts:
          path: reports/dependency-check-report.json
          destination: depcheck-artifact

workflows:
  version: 2
  webgoat:
    jobs:
      - build
      - test:
          requires:
            - build
      - odc-backend:
          requires:
            - test
EOF

#Go back to the DevSecOps Box machine to create a new file called run-depcheck.sh with the following contents.
#!/bin/sh

DATA_DIRECTORY="$PWD/data"
REPORT_DIRECTORY="$PWD/reports"

if [ ! -d "$DATA_DIRECTORY" ]; then
  echo "Initially creating persistent directories"
  mkdir -p "$DATA_DIRECTORY"
  chmod -R 777 "$DATA_DIRECTORY"

  mkdir -p "$REPORT_DIRECTORY"
  chmod -R 777 "$REPORT_DIRECTORY"
fi

cd webgoat-container

# Make sure we are using the latest version
docker pull owasp/dependency-check

docker run --rm \
  --volume $(pwd):/src \
  --volume "$DATA_DIRECTORY":/usr/share/dependency-check/data \
  --volume "$REPORT_DIRECTORY":/reports \
  owasp/dependency-check \
  --scan /src \
  --format "JSON" \
  --project "Webgoat" \
  --failOnCVSS 8 \
  --out /reports


--Optional: Software Component Analysis Using Snyk--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp

wget -O /usr/local/bin/snyk https://github.com/snyk/cli/releases/download/v1.984.0/snyk-linux
chmod +x /usr/local/bin/snyk
snyk --help
snyk test --json .

snyk auth YOUR_API_TOKEN_HERE
export SNYK_TOKEN=YOUR_TOKEN_HERE
snyk test --json .

npm install
mkdir -p /etc/apt/keyrings
curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
NODE_MAJOR=20
echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | tee /etc/apt/sources.list.d/nodesource.list
apt update
apt install nodejs -y
npm install

snyk test --json . > output.json
cat output.json
snyk test --strict-out-of-sync=false --json . > output.json


--Optional: How To Embed Snyk Into GitLab--
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

oast-snyk:
  stage: build
  image: node:alpine3.10
  before_script:
    - wget -O snyk https://github.com/snyk/cli/releases/download/v1.1156.0/snyk-alpine
    - chmod +x snyk
    - mv snyk /usr/local/bin/
  script:
    - npm install
    - snyk auth $SNYK_TOKEN
    - snyk test --json > snyk-results.json
    - cat snyk-results.json
  artifacts:
    paths:
      - snyk-results.json
    when: always
    expire_in: one week
  allow_failure: true

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: How To Embed Snyk Into GitHub Actions--
name: Django                                  # workflow name

on:
  push:
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                    # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py check

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py test taskManager

  oast-snyk:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - uses: actions/checkout@master
      - uses: snyk/actions/setup@master
      - uses: actions/setup-go@v1
        with:
          go-version: "1.13"

      - uses: actions/setup-node@v2
        with:
          node-version: '10.x'

      - name: Install Node modules
        run: npm install

      - name: Run Snyk
        run: snyk test --json > snyk-results.json
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        continue-on-error: true             # allow the build to fail, similar to allow_failure: true

      - uses: actions/upload-artifact@v2
        with:
          name: Snyk
          path: snyk-results.json
        if: always()        # what is this for?

  integration:
    runs-on: ubuntu-20.04
    needs: oast-snyk
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."


--Optional: How To Embed Snyk Into CircleCI--
mkdir -p .circleci
jobs:
  build:
    docker:
      - image: python:3.6                   # similar to "image" in GitLab
    steps:
      - checkout
      - run: |                              # similar to "script" in GitLab
          pip install -r requirements.txt
          python manage.py check

  test:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: |
          pip install -r requirements.txt
          python manage.py test taskManager

  oast-snyk:
    docker:
      - image: node:alpine3.10
    steps:
      - checkout

      - run: 
          command: |
            wget -O snyk https://github.com/snyk/cli/releases/download/v1.1156.0/snyk-alpine
            chmod +x snyk
            mv snyk /usr/local/bin/
            npm install
            snyk auth $SNYK_TOKEN
            snyk test --json > snyk-results.json || true

      - store_artifacts:
          path: snyk-results.json
          destination: snyk-artifact
          when: always

  integration:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: on_fail         # Even if the job fails, continue to the next stages

  prod:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "This is a deploy step."

workflows:
  version: 2
  django:
    jobs:
      - build
      - test:
          requires:
            - build
      - oast-snyk:
          requires:
            - test
      - integration:
          requires:
            - oast-snyk
      - prod:
          type: approval
          requires:
            - integration


--Optional: Software Component Analysis Using NPM Audit--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
curl -sL https://deb.nodesource.com/setup_14.x | bash -
apt install nodejs -y
npm audit -h
npm install
npm audit
npm audit --json | tee results.json


--Optional: Software Component Analysis Using AuditJS--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp

mkdir -p /etc/apt/keyrings
curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
NODE_MAJOR=20
echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | tee /etc/apt/sources.list.d/nodesource.list
apt update

apt install nodejs -y
npm install -g auditjs
auditjs -h
auditjs ossi --help
auditjs ossi
npm install
auditjs ossi
auditjs ossi -q -j | tee auditjs-output.json


--Optional: How To Embed AuditJS Into GitLab--
git clone https://gitlab.practical-devsecops.training/pdso/nodejs.git nodejs
cd nodejs
git remote rename origin old-origin
git remote add origin git@gitlab-ce-8lw53ql9:root/nodejs.git
git push -u origin --all

image: node:alpine3.10

cache:
  paths:
  - node_modules/

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  script:
    - npm install

test:
  stage: test
  script:
    - echo "This is an test step"

auditjs:
  stage: test
  script:
    - docker run --rm -v $(pwd):/src -w /src hysnsec/auditjs ossi -q -j | tee auditjs-output.json
  artifacts:
    paths: [auditjs-output.json]
    when: always # What is this for?
    expire_in: one week
  allow_failure: true  #<--- allow the build to fail but don't mark it as such

integration:
  stage: integration
  script:
    - echo "This is an integration step"

prod:
  stage: prod
  script:
    - echo "This is a deploy step"


--Optional: Software Component Analysis Using bundler-audit--
git clone https://gitlab.practical-devsecops.training/pdso/rails.git webapp
cd webapp
curl -fsSL https://github.com/rbenv/rbenv-installer/raw/HEAD/bin/rbenv-installer | bash
export PATH="~/.rbenv/bin:$PATH"
cat Gemfile
rbenv install 2.6.5
apt update
apt-get install build-essential libreadline-dev -y
rbenv install --verbose 2.6.5
export PATH="/root/.rbenv/versions/2.6.5/bin:$PATH"
ruby --version
gem install --user-install bundler-audit
export PATH="~/.gem/ruby/2.6.0/bin/:$PATH"
bundle-audit -h
bundle-audit


--Optional: How To Embed bundler-audit Into GitLab--
git clone https://gitlab.practical-devsecops.training/pdso/rails.git rails
cd rails
git remote rename origin old-origin
git remote add origin git@gitlab-ce-8lw53ql9:root/rails.git
git push -u origin --all

image: docker:20.10

services:
  - docker:dind

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  script:
    - echo "This is a build step"

test:
  stage: test
  script:
    - echo "This is a test step"

bundler-audit:
  stage: test
  script:
    - docker run --rm -v $(pwd):/src -w /src hysnsec/bundle-audit check --format json --output bundle-audit-output.json
  artifacts:
    paths: [bundle-audit-output.json]
    when: always # What is this for?
    expire_in: one week
  allow_failure: true  #<--- allow the build to fail but don't mark it as such

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step"
  when: manual # Continuous Delivery


--Optional: How To Embed bundler-audit Into GitHub Actions--
git clone https://gitlab.practical-devsecops.training/pdso/rails.git
cd rails
git remote rename origin old-origin
git remote add origin https://github.com/username/rails.git
git status
git push -u origin main
mkdir -p .github/workflows

name: rails                                  # workflow name

on:
  push:
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                    # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v2

      - run: echo "This is a build step"

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v2

      - run: echo "This is a test step"

  bundler-audit:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - uses: actions/checkout@v2

      - run: docker run --rm -v $(pwd):/src -w /src hysnsec/bundle-audit check --format json --output bundle-audit-output.json
        continue-on-error: true             # allow the build to fail, similar to "allow_failure: true" in GitLab

      - uses: actions/upload-artifact@v2
        with:
          name: bundler-audit
          path: bundle-audit-output.json
        if: always()                        # what is this for?

  integration:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."


--Optional: How To Embed bundler-audit Into CircleCI--
git clone https://gitlab.practical-devsecops.training/pdso/rails.git
cd rails
git remote rename origin old-origin
git remote add origin https://github.com/username/rails.git
git status
git checkout -b main
git push -u origin main
ssh-keygen -t ed25519 -f ~/.ssh/project_key -C <YOUR_GITHUB_EMAIL>
more ~/.ssh/project_key.pub
more ~/.ssh/project_key
mkdir -p .circleci

cat >.circleci/config.yml<<EOF
jobs:
  build:
    steps:
      - checkout
      - run: echo "This is a build step"    # similar to "script" in GitLab

  test:
    steps:
      - checkout
      - run: echo "This is a test step"

  bundler-audit:
    machine: true
    steps:
      - checkout

      - run: 
          command: docker run --rm -v $(pwd):/src -w /src hysnsec/bundle-audit check --format json --output bundle-audit-output.json || true

      - store_artifacts:
          path: bundle-audit-output.json
          destination: bundler-audit-artifact
          when: always

  integration:
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: always                    # Even if the job fails, continue to the next stages

  prod:
    steps:
      - checkout
      - run: echo "This is a deploy step."

workflows:
  version: 2
  rails:
    jobs:
      - build
      - test:
          requires:
            - build
      - bundler-audit:
          requires:
            - test
      - integration:
          requires:
            - bundler-audit
      - prod:
          type: approval
          requires:
            - integration
EOF

git add .circleci/config.yml
git commit -m "Add CircleCI config"
git push origin main


--Optional: Software Component Analysis Using Composer Audit--
git clone https://gitlab.practical-devsecops.training/pdso/php.git
cd php
apt update && apt install -y php7.4 php7.4-gd php7.4-intl php7.4-xsl php7.4-mbstring
php -r "copy('https://getcomposer.org/installer', 'composer-setup.php');"
php composer-setup.php --install-dir=/usr/local/bin --filename=composer
php -r "unlink('composer-setup.php');"
composer audit -h
composer install
composer audit
composer audit -f json | tee results.json


--Optional: How To Embed Composer Into GitLab--
git clone https://gitlab.practical-devsecops.training/pdso/php.git
cd php
git remote rename origin old-origin
git remote add origin git@gitlab-ce-8lw53ql9:root/php.git
git push -u origin --all

image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  script:
    - echo "This is a build step"

test:
  stage: test
  script:
    - echo "This is a test step"

oast-backend:
  stage: build 
  image: php:7.4
  before_script:
    - php -r "copy('https://getcomposer.org/installer', 'composer-setup.php');"
    - php composer-setup.php --install-dir=/usr/local/bin --filename=composer
    - php -r "unlink('composer-setup.php');"
    - apt update
    - apt install unzip
  script:
    - composer install
    - composer audit -f json | tee composer-output.json
  artifacts:
    paths: [composer-output.json]
    when: always
  allow_failure: true

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: Addressing Issues via Renovate on GitHub--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
mkdir -p /etc/apt/keyrings
curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
NODE_MAJOR=20
echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | tee /etc/apt/sources.list.d/nodesource.list
apt update
apt install nodejs -y
npm install -g renovate
renovate -h
renovate
echo "deb http://ppa.launchpad.net/git-core/ppa/ubuntu $(lsb_release -cs) main"  >> /etc/apt/sources.list
apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys E1DD270288B4E6030699E45FA1715D88E1DF1F24
apt update && apt install git -y
git --version
renovate
git config --global user.name "your_username"
export RENOVATE_TOKEN="<your_token>"
renovate <github_username>/webapp


--Optional: Addressing Issues via Renovate on GitLab--
git clone git@gitlab-ce-8lw53ql9:root/django-nv.git
cd django-nv
mkdir -p /etc/apt/keyrings
curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
NODE_MAJOR=20
echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | tee /etc/apt/sources.list.d/nodesource.list
apt update
apt install nodejs -y
npm install -g renovate

#Please use the nano/vim text editor to modify the configuration file and create the renovate-config.js file.
module.exports = {
  endpoint: 'https://gitlab-ce-8lw53ql9.lab.practical-devsecops.training/api/v4/',
  token: '<your_gitlab_token>',
  platform: 'gitlab',
  onboardingConfig: {
    extends: ['config:recommended'],
  },
  repositories: ['root/django-nv'],
};

export RENOVATE_CONFIG_FILE="/django-nv/renovate-config.js"
export NODE_TLS_REJECT_UNAUTHORIZED=0
renovate


--Optional: Addressing Issues via Dependabot on GitLab--
git clone git@gitlab-ce-8lw53ql9:root/django-nv.git
cd django-nv
mkdir /django-nv/.gitlab

cat > /django-nv/.gitlab/dependabot.yml <<EOF
version: 2
updates:
  - package-ecosystem: npm
    directory: /
EOF

image: docker:20.10

services:
  - docker:dind

stages:
  - build

.npm:
  stage: build
  image:
    name: docker.io/andrcuns/dependabot-gitlab:0.11.0
    entrypoint: [""]
  variables:
    GIT_STRATEGY: none
    PACKAGE_MANAGER: npm
    RAILS_ENV: production
    SETTINGS__GITLAB_URL: $CI_SERVER_URL
    SETTINGS__STANDALONE: "true"
  before_script:
    - cd /home/dependabot/app
  script:
    - bundle exec rake "dependabot:update[$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME,$PACKAGE_MANAGER,/]"

dependabot:
  extends: .npm
  when: manual


--Optional: Software Component Analysis Using OSV Scanner--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
apt update
apt install npm -y
npm install
wget -O /usr/bin/osv-scanner https://github.com/google/osv-scanner/releases/download/v1.4.0/osv-scanner_1.4.0_linux_amd64 && sudo chmod +x /usr/bin/osv-scanner
osv-scanner --help
osv-scanner .
osv-scanner -L requirements.txt
osv-scanner -L package-lock.json --format json
osv-scanner -L package-lock.json --format json --output osv-output.json

#For advanced scanning, we offer two scanning models:
#Experimental Local DB Scanning
#False Positive Analysis Scanning

osv-scanner --experimental-local-db .
zipinfo /root/.cache/osv-scanner/npm/all.zip
osv-scanner --experimental-offline .
osv-scanner -L requirements.txt

cat > /webapp/config.toml <<EOF
[[IgnoredVulns]]
id = "PYSEC-2020-31"
reason = "outdated information"

[[IgnoredVulns]]
id = "PYSEC-2020-32"
reason = "outdated information"
EOF

osv-scanner --config=/webapp/config.toml -L requirements.txt


--Optional: How To Embed OSV Scanner Into GitLab--
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

osv-scanner:
  stage: test
  image: golang:1.21.1-alpine3.18
  before_script:
    - apk add npm
    - npm install
  script:
    - go install github.com/google/osv-scanner/cmd/osv-scanner@v1
    - osv-scanner --json . > osv-report.json
  artifacts:
    paths: [osv-report.json]
    when: always 
  allow_failure: true

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: Software Component Analysis Using Semgrep--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install semgrep==1.31.0
semgrep --help
semgrep ci --supply-chain
semgrep login
semgrep ci --supply-chain
semgrep ci --help | grep "Output formats" -A9
semgrep ci --supply-chain --output semgrep-sca-output.json --json


--Optional: Software Component Analysis Using Trivy--
wget https://github.com/aquasecurity/trivy/releases/download/v0.48.1/trivy_0.48.1_Linux-64bit.deb && dpkg -i trivy_*.deb
trivy -h
git clone https://gitlab.practical-devsecops.training/pdso/django.nv.git webapp
cd webapp
trivy filesystem .


--Optional: How To Embed Trivy Into GitLab--
image: docker:20.10

services:
  - docker:dind

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

trivy:
  stage: test
  script:
    - docker run --rm -v $(pwd):/src hysnsec/trivy fs . --exit-code 1 -f json -o trivy-report.json
  artifacts:
    paths: [trivy-report.json]
    when: always # What is this for?
    expire_in: one week
  allow_failure: true   #<--- allow the build to fail but don't mark it as such

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: Software Component Analysis Using Sandworm--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
NODE_MAJOR=20
echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | tee /etc/apt/sources.list.d/nodesource.list
apt update
apt install nodejs -y
npm install -g @sandworm/audit
sandworm --help
sandworm audit
npm install
sandworm audit
ls -l sandworm
sandworm audit --skip-csv
cat sandworm/owasp-nodejs-goat@1.3.0-report.json | jq 'keys'
cat sandworm/owasp-nodejs-goat@1.3.0-report.json | jq '.dependencyVulnerabilities'
cat sandworm/owasp-nodejs-goat@1.3.0-report.json | jq '.dependencyVulnerabilities | length'
cat sandworm/owasp-nodejs-goat@1.3.0-report.json | jq '.dependencyVulnerabilities[] | "\(.name) \(.severity)"'
sandworm audit --help
sandworm audit
sandworm-audit --fail-on='["dependencies.high"]'

#exit 0: Indicates that the command or program executed successfully without any errors.
#exit 1 or non-zero : Catch-all exit code for a variety of general errors.


--Optional: Addressing Issues With Sandworm--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
NODE_MAJOR=20
echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | tee /etc/apt/sources.list.d/nodesource.list
apt update
apt install nodejs -y
npm install -g @sandworm/audit
sandworm resolve --help
npm install
sandworm audit
sandworm audit --skip-license-issues
cat sandworm/owasp-nodejs-goat@1.3.0-report.json | jq '.dependencyVulnerabilities[] | select(.severity == "critical") | .githubAdvisoryId'
sandworm resolve --issueId GHSA-v8w9-2789-6hhr
sandworm audit --skip-license-issues




----SAST (Static Analysis) in CI/CD Pipeline----
#A technique to analyze source code, binary and byte code for security vulnerabilities without running the code/binary/byte code.
#Code is not run, but statically examined, thus called static analysis.
#Run SAST in QA, not Prod

#Python - Bandit
#Ruby on Rails - Brakeman
#PHP - phpcs-security-audit/rips
#Go - Go AST Scanner(GAS)
#Java - Find-Sec-Bugs

#Secrets Endemic - people storing secrets in version control, config, etc
#Regex based scanner - looks for known secrets patterns in code
#Tools: git-secrets, gitrob, etc
#Entropy based scanner - looks for data which is random, lacks order or predicability
#Tools: trufflehog, repo-scanner, etc


--Secrets Scanning Using TruffleHog--
wget https://github.com/trufflesecurity/trufflehog/releases/download/v3.28.0/trufflehog_3.28.0_linux_amd64.tar.gz
tar -xvf trufflehog_3.28.0_linux_amd64.tar.gz
chmod +x trufflehog
mv trufflehog /usr/local/bin/

#TruffleHog v3 written in Golang, it can scan repository directly instead of cloning it locally
trufflehog --help
trufflehog git http://gitlab-ce-8lw53ql9.lab.practical-devsecops.training/root/django-nv.git --json
cat secret.json | jq


--Embed TruffleHog into GitLab--
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

git-secrets:
  stage: build
  script:
    - docker run -v $(pwd):/src --rm hysnsec/trufflehog filesystem --directory=/src --json | tee trufflehog-output.json
  artifacts:
    paths: [trufflehog-output.json]
    when: always  # What is this for?
    expire_in: one week
  allow_failure: true

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Static Analysis using Bandit--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install bandit==1.7.4
bandit --help
bandit -r . -f json | tee bandit-output.json
bandit -r . -l
bandit -r . -ll
bandit -r . -lll

#Exit Codes
0	This code is returned when Bandit finds no security issues in the scanned code.
1	Bandit issues this code when it detects security issues of the specified severity level or higher.
2	If an error occurs during the Bandit scan, such as an invalid command-line argument or an issue with the code being scanned.


--Embed Bandit into GitLab--
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

sast:
  stage: build
  script:
    - docker pull hysnsec/bandit  # Download bandit docker container
    # Run docker container, please refer docker security course, if this doesn't make sense to you.
    - docker run --user $(id -u):$(id -g) -v $(pwd):/src --rm hysnsec/bandit -r /src -f json -o /src/bandit-output.json
  artifacts:
    paths: [bandit-output.json]
    when: always
  allow_failure: true   #<--- allow the build to fail but don't mark it as such

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--False Positive Analysis (FPA)--
#bandit-baseline.json is basically the "ignore" file for false positives
git clone https://gitlab.practical-devsecops.training/pdso/dvpa-api
cd dvpa-api
pip3 install bandit==1.7.4
bandit --help
bandit -r .
bandit -r . -f json | tee baseline.json
bandit -r . -f json | jq '.results | length'
bandit -r . -f json -b baseline.json
bandit -r . -f json -b baseline.json | jq '.results | length'

#Create a baseline file for the dvpa-api source code. Include any issues marked as False Positive. Save the baseline file at /dvpa-api/baseline.json. Specifically, mark the issue in line 132 of the file ./flaskblog/blogapi/dashboard.py, related to potential SQL injection, as a false positive
cat > baseline.json <<'EOF'
{
  "results": [
    {
      "code": "132         cur.execute(\n133             f\"INSERT INTO posts (`body`, `slug`, `author`, `title`) VALUES (%s, %s, %s, %s)\",\n134             [body, slug, claim.get(\"id\"), title])\n",
      "col_offset": 12,
      "filename": "./flaskblog/blogapi/dashboard.py",
      "issue_confidence": "MEDIUM",
      "issue_cwe": {
        "id": 89,
        "link": "https://cwe.mitre.org/data/definitions/89.html"
      },
      "issue_severity": "MEDIUM",
      "issue_text": "Possible SQL injection vector through string-based query construction.",
      "line_number": 133,
      "line_range": [
        133
      ],
      "more_info": "https://bandit.readthedocs.io/en/1.7.4/plugins/b608_hardcoded_sql_expressions.html",
      "test_id": "B608",
      "test_name": "hardcoded_sql_expressions"
    }
  ]
}
EOF

#Please run the scan and check using grep to ensure that the 132 issues marked as False Positives do not appear in the scan results.
bandit -r . -f json -b baseline.json
bandit -r . -f json -b baseline.json | grep "132 cur.execute"


--Static Analysis using Brakeman--
git clone https://gitlab.practical-devsecops.training/pdso/rails.git webapp
cd webapp
apt update
apt install ruby-full -y
gem install brakeman -v 5.2.1
brakeman -h
brakeman -f json | tee result.json

cat > brakeman.ignore <<EOF
{
    "ignored_warnings": [
        {
          "fingerprint": "febb21e45b226bb6bcdc23031091394a3ed80c76357f66b1f348844a7626f4df",
          "note": "ignore XSS"
        }
    ]
}
EOF

brakeman -f json -i brakeman.ignore | tee result.json


--Optional: How To Embed TruffleHog Into Jenkins--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("git-secrets") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {     // Allow the sast stage to fail
                    git branch: 'main',
                    credentialsId: 'gitlab-auth',
                    url: 'http://gitlab-ce-8lw53ql9.lab.practical-devsecops.training/root/django-nv.git'
                    sh "docker run -v \$(pwd):/src --rm hysnsec/trufflehog filesystem --directory=/src --json | tee trufflehog-output.json"
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'trufflehog-output.json', fingerprint: true
                }
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step."
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'skipped')
        }
        always {
            deleteDir()                     // clean up workspace
        }
    }
}


--Optional: How To Embed TruffleHog Into GitHub Actions--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv.git
cd django.nv
git remote rename origin old-origin
git remote add origin https://github.com/username/django.nv.git
git status
git push -u origin main
mkdir -p .github/workflows

cat >.github/workflows/main.yaml<<EOF
name: Django                                  # workflow name

on:
  push:
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                    # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py check

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py test taskManager

  secret_scanning:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - uses: actions/checkout@v2

      - run: docker run --rm -v $(pwd):/src hysnsec/trufflehog filesystem --directory=/src --json > trufflehog-output.json
        continue-on-error: true             # allow the build to fail, similar to "allow_failure: true" in GitLab

      - uses: actions/upload-artifact@v2
        with:
          name: TruffleHog
          path: trufflehog-output.json
        if: always()                        # what is this for?

  integration:
    runs-on: ubuntu-20.04
    needs: secret_scanning
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."
EOF

git add .github/workflows/main.yaml
git commit -m "Add github workflows"
git push origin main


--Optional: How To Embed TruffleHog Into CircleCI--
jobs:
  build:
    docker:
      - image: python:3.6                   # similar to "image" in GitLab
    steps:
      - checkout
      - run: |                              # similar to "script" in GitLab
          pip install -r requirements.txt
          python manage.py check

  test:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: |
          pip install -r requirements.txt
          python manage.py test taskManager

  secret_scanning:
    machine: true
    steps:
      - checkout

      - run:
          command: docker run --rm -v $(pwd):/src hysnsec/trufflehog filesystem --directory=/src --json > trufflehog-output.json || true

      - store_artifacts:
          path: trufflehog-output.json
          destination: trufflehog-artifact
          when: always

  integration:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: on_fail         # Even if the job fails, continue to the next stages

  prod:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "This is a deploy step."

workflows:
  version: 2
  django:
    jobs:
      - build
      - test:
          requires:
            - build
      - secret_scanning:
          requires:
            - test
      - integration:
          requires:
            - secret_scanning
      - prod:
          type: approval
          requires:
            - integration


--Optional: Secrets Scanning Using Detect-Secrets--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install detect-secrets==1.4.0
detect-secrets --help
detect-secrets scan
detect-secrets scan > secrets-output.json
echo "q\n" | detect-secrets audit secrets-output.json


--Optional: Secrets Scanning with Talisman--
curl --silent https://raw.githubusercontent.com/thoughtworks/talisman/master/global_install_scripts/install.bash > /tmp/install_talisman.bash && /bin/bash /tmp/install_talisman.bash pre-commit
curl --silent https://raw.githubusercontent.com/thoughtworks/talisman/master/global_install_scripts/install.bash > /tmp/install_talisman.bash && /bin/bash /tmp/install_talisman.bash pre-push
git clone http://gitlab-ce-8lw53ql9.lab.practical-devsecops.training/root/django-nv.git webapp
cd webapp
cp ~/.ssh/id_rsa .
git add id_rsa
git commit -m "Add private key"
talisman -h
source ~/.bashrc
talisman --scan


--Optional: Secrets Scanning Using Semgrep--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install semgrep==1.30.0
semgrep --help
semgrep --config "p/secrets"
semgrep login
semgrep --config "p/secrets"


--Optional: Secrets Scanning Using Gitleaks--
wget https://github.com/gitleaks/gitleaks/releases/download/v8.18.1/gitleaks_8.18.1_linux_x64.tar.gz && tar -xvzf gitleaks_8.18.1_linux_x64.tar.gz && mv gitleaks /usr/local/bin
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
gitleaks --help
gitleaks detect .
gitleaks detect . --report-path gitleaks-output.txt
cat gitleaks-output.txt
gitleaks detect . --report-path gitleaks-redact50.txt --redact=50


--Optional: How To Embed Bandit Into Jenkins--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("sast") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    sh "docker run -v \$(pwd):/src --rm hysnsec/bandit -r /src -f json -o /src/bandit-output.json"
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'bandit-output.json', fingerprint: true
                }
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step."
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'skipped')
        }
        always {
            deleteDir()                     // clean up workspace
        }
    }
}


--Optional: How To Embed Bandit Into GitHub Actions--
name: Django                                  # workflow name

on:
  push:
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                    # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py check

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py test taskManager

  sast:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - uses: actions/checkout@v2

      - run: docker run --rm -v $(pwd):/src hysnsec/bandit -r /src -f json -o /src/bandit-output.json
        continue-on-error: true             # allow the build to fail, similar to allow_failure: true

      - uses: actions/upload-artifact@v2
        with:
          name: Bandit
          path: bandit-output.json
        if: always()                        # what is this for?

  integration:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."


--Optional: How To Embed Bandit Into CircleCI--
jobs:
  build:
    docker:
      - image: python:3.6                   # similar to "image" in GitLab
    steps:
      - checkout
      - run: |                              # similar to "script" in GitLab
          pip install -r requirements.txt
          python manage.py check

  test:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: |
          pip install -r requirements.txt
          python manage.py test taskManager

  sast:
    machine: true
    steps:
      - checkout

      - run: docker run --rm -v $(pwd):/src hysnsec/bandit -r /src -f json -o /src/bandit-output.json || true

      - store_artifacts:
          path: bandit-output.json
          destination: bandit-artifact
          when: always

  integration:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: on_fail           # Even if the job fails, continue to the next stages

  prod:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "This is a deploy step."

workflows:
  version: 2
  django:
    jobs:
      - build
      - test:
          requires:
            - build
      - sast:
          requires:
            - test
      - integration:
          requires:
            - sast
      - prod:
          type: approval
          requires:
            - integration


--Optional: How To Fix the Issues Reported by Bandit--
git clone https://gitlab.practical-devsecops.training/pdso/dvpa-api webapp
cd webapp
pip3 install bandit==1.7.4
bandit --help
bandit -r .


--Optional: Static Analysis Using Gosec--
git clone https://gitlab.practical-devsecops.training/pdso/golang.git webapp
cd webapp
curl -s https://dl.google.com/go/go1.17.4.linux-amd64.tar.gz | tar xvz -C /usr/local
export GOROOT=/usr/local/go
export GOPATH=$HOME/go
export PATH=$GOPATH/bin:$GOROOT/bin:$PATH
curl -sfL https://raw.githubusercontent.com/securego/gosec/master/install.sh | sh -s -- -b $(go env GOPATH)/bin v2.4.0
go get -u github.com/securego/gosec/v2/cmd/gosec
gosec --help
gosec ./...
gosec -exclude=G104 ./...


--Optional: How To Embed Gosec Into GitLab--
git clone https://gitlab.practical-devsecops.training/pdso/golang.git golang
cd golang
git remote rename origin old-origin
git remote add origin git@gitlab-ce-8lw53ql9:root/golang.git
git push -u origin --all

image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

sast:
  stage: build
  script:
    - docker run --rm -v $(pwd):/src -w /src securego/gosec -fmt json -out gosec-output.json ./...
  artifacts:
    paths: [gosec-output.json]
    when: always
  allow_failure: true

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: Embed Gosec Into Jenkins--
git clone https://gitlab.practical-devsecops.training/pdso/golang.git golang
cd golang
git remote rename origin old-origin
git remote add origin http://gitlab-ce-8lw53ql9.lab.practical-devsecops.training/root/golang.git
git checkout -b main
git push -u origin main

pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            steps {
                echo "This is a build step."
            }
        }
        stage("sast") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    sh "docker run --rm -w /src -v \$(pwd):/src securego/gosec -fmt json -out /src/gosec-output.json /src/..."
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'gosec-output.json', fingerprint: true
                }
            }
        }
        stage("integration") {
            steps {
                // Allow the stage to fail
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step."
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'skipped')
        }
        always {
            deleteDir()                     // clean up workspace
        }
    }
}


--Optional: Static Analysis Using Semgrep--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install semgrep==1.30.0
semgrep --help
semgrep --lang python -e "os.system(...)" .
semgrep --lang python -e "os.system(...)"  . --json | jq
semgrep --lang python -e "DEBUG =True" --include settings.py .
semgrep --lang python -e '$X = $Y' .
semgrep --lang python -e '$FUNC(request)' .


--Optional: How To Write Custom Rule in Semgrep--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install semgrep==1.30.0
semgrep --help
semgrep --lang python -e '$X = $Y' .
semgrep --lang python -e '$X.objects.get' .

cat > command_injection.yaml <<EOF
rules:
- id: possible-command-injection
  patterns:
  - pattern: os.system(...)
  - pattern-not: os.system("...")
  message: Possible Command Injection
  languages:
  - python
  severity: WARNING
EOF

semgrep --lang python -f command_injection.yaml .

cat > find_project_db_get_call.yaml <<EOF
rules:
- id: find-get-project-db-value
  patterns:
  - pattern: Project.objects.get(...)
  - pattern-inside: |
      def \$FUNC(request):
        ...
  message: Get project db value
  languages:
  - python
  severity: WARNING
EOF

semgrep --lang python -f find_project_db_get_call.yaml .


--Optional: Hunting Vulnerability Using Semgrep--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install semgrep==1.31.0
semgrep --help

cat > csrf_hunting.yaml <<EOF
rules:
- id: possible-csrf
  patterns:
  - pattern-inside: | 
      @csrf_exempt
      def \$FUNC(\$X):
          ...
  message: |
    Possible CSRF
  languages:
  - python
  severity: WARNING

- id: no-csrf-middleware
  patterns:
  - pattern: MIDDLEWARE_CLASSES=(...)
  - pattern-not: MIDDLEWARE_CLASSES=(...,'django.middleware.csrf.CsrfViewMiddleware',...)
  message: |
    No CSRF middleware
  languages:
  - python
  severity: WARNING
EOF

semgrep -f csrf_hunting.yaml .

cat > debug_enable.yaml <<EOF 
rules:
- id: debug-enabled
  patterns:
  - pattern: DEBUG=True
  message: |
    Detected Django app with DEBUG=True. Do not deploy to production with this flag enabled
    as it will leak sensitive information.
  metadata:
    cwe: 'CWE-489: Active Debug Code'
    owasp: 'A6: Security Misconfiguration'
    references:
    - https://blog.scrt.ch/2018/08/24/remote-code-execution-on-a-facebook-server/
  severity: WARNING
  languages:
  - python
EOF

semgrep -f debug_enable.yaml .
semgrep --config "p/bandit" .

cat > insecure_redirect.yaml <<EOF
rules:
- id: CWE-601
  pattern: |
    return redirect(request.\$M.get(...))
  message: Insecure Redirect
  severity: WARNING
  languages:
  - python
EOF

semgrep -f insecure_redirect.yaml


--Optional: How to Fix The Issues Reported by Semgrep--
git clone https://gitlab.practical-devsecops.training/pdso/dvpa webapp
cd webapp
pip3 install semgrep==1.31.0
semgrep --help

#Before we run semgrep, we need to create the rules file, semgrep_rules.yaml. These rules will help us find vulnerabilities in the code. You can use any text editor to create this file with the following content.

rules:
- id: avoid-pyyaml-load
  metadata:
    owasp: 'A8: Insecure Deserialization'
    cwe: 'CWE-502: Deserialization of Untrusted Data'
    references:
    - https://github.com/yaml/pyyaml/wiki/PyYAML-yaml.load(input)-Deprecation
    - https://nvd.nist.gov/vuln/detail/CVE-2017-18342
  languages:
  - python
  message: |
    Avoid using `load()`. `PyYAML.load` can create arbitrary Python
    objects. A malicious actor could exploit this to run arbitrary
    code. Use `safe_load()` instead.
  fix: yaml.safe_load($FOO)
  severity: ERROR
  patterns:
  - pattern-inside: |
      import yaml
      ...
      yaml.load($FOO)
  - pattern: yaml.load($FOO)

- id: possible-sqli
  metadata:
    owasp: 'A1: Injection'
    references:
    - https://owasp.org/www-community/attacks/SQL_Injection
  languages:
  - python
  message: |
    Possible SQL Injection
  severity: WARNING
  patterns:
  - pattern: $X.execute(...)
  - pattern-not: $X.execute(..., [...])
  - pattern-not: $X.execute("...")

semgrep -f semgrep_rules.yaml .
cur.execute(f"SELECT * FROM users WHERE email=%s AND password=%s", [username, hashsed_password ])
semgrep -f semgrep_rules.yaml .


--Optional: How To Embed Semgrep Into GitLab--
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

semgrep:
  stage: build
  script:
   - docker run --rm -v ${PWD}:/src returntocorp/semgrep semgrep --config auto --output semgrep-output.json --json
  artifacts:
    paths: [semgrep-output.json]
    when: always  # What is this for?
    expire_in: one week
  allow_failure: true    #<--- allow the build to fail but don't mark it as such

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: ow To Embed Semgrep Into Jenkins--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            agent { 
                docker { 
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent { 
                docker { 
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("sast") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {     // Allow the sast stage to fail
                    sh "docker run --rm -v \${PWD}:/src returntocorp/semgrep semgrep --config auto --output semgrep-output.json --json"
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'semgrep-output.json', fingerprint: true
                }
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step."
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'canceled')
        }
        always { 
            deleteDir()                     // clean up workspace
            dir("${WORKSPACE}@tmp") {       // clean up tmp directory
                deleteDir()
            }
            dir("${WORKSPACE}@script") {    // clean up script directory
                deleteDir()
            }
        }
    }
}


--Optional: How To Embed Semgrep Into GitHub Actions--
name: Django                                  # workflow name

on:
  push:                                       
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                     # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v4

      - name: Setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py check

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v4

      - name: Setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py test taskManager

  semgrep:
    name: semgrep/ci
    needs: test
    runs-on: ubuntu-20.04
    steps:
      - uses: actions/checkout@v4
      - run: docker run --rm -v "${PWD}:/src" returntocorp/semgrep semgrep --config auto --output semgrep-output.json --json
      - uses: actions/upload-artifact@v3
        with:
          name: semgrep
          path: semgrep-output.json
        continue-on-error: true             # allow the build to fail, similar to "allow_failure: true" in GitLab
        if: always()                        # what is this for?

  integration:
    runs-on: ubuntu-20.04
    needs: semgrep
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."


--Optional: How To Embed Semgrep Into CircleCI--
jobs:
  build:
    docker:
      - image: python:3.6                   # similar to "image" in GitLab
    steps:
      - checkout
      - run: |                              # similar to "script" in GitLab
          pip install -r requirements.txt
          python manage.py check

  test:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: |
          pip install -r requirements.txt
          python manage.py test taskManager

  semgrep:
    machine: true
    steps:
      - checkout
      - run: docker run --rm -v ${PWD}:/src returntocorp/semgrep semgrep --config auto --output semgrep-output.json --json || true
      - store_artifacts:
          path: semgrep-output.json
          destination: semgrep-artifact

  integration:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: on_fail         # Even if the job fails, continue to the next stages

  prod:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "This is a deploy step."

workflows:
  version: 2
  django:
    jobs:
      - build
      - test:
          requires:
            - build
      - semgrep:
          requires:
            - test
      - integration:
          requires:
            - semgrep
      - prod:
          type: approval
          requires:
            - integration


--Optional: How To Embed Gitleaks Into GitLab--
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

gitleaks:
  stage: build
  script:
    - docker pull zricethezav/gitleaks
    - docker run --user $(id -u):$(id -g) -v $(pwd):/path -w /path zricethezav/gitleaks detect . --report-path gitleaks-output.json
  artifacts:
    paths: [gitleaks-output.json]
    when: always
    expire_in: one week
  allow_failure: true   #<--- allow the build to fail

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: Static Analysis Using Hadolint--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
wget https://github.com/hadolint/hadolint/releases/download/v1.18.0/hadolint-Linux-x86_64
mv hadolint-Linux-x86_64 /usr/local/bin/hadolint
chmod +x /usr/local/bin/hadolint
hadolint --help
hadolint Dockerfile
cat -n Dockerfile

cat > Dockerfile <<EOL
# FROM python base image
FROM python:3-alpine3.15

# COPY startup script
COPY . /app

WORKDIR /app

RUN apk add --no-cache gawk=5.0.1-r0 sed=4.7-r0 bash=5.0.11-r1 grep=3.3-r0 bc=1.07.1-r1 coreutils=8.31-r0
RUN pip install -r requirements.txt
RUN chmod +x reset_db.sh && bash reset_db.sh

# EXPOSE port 8000 for communication to/from server
EXPOSE 8000

# CMD specifies the command to execute container starts running.
CMD ["/app/run_app_docker.sh"]
EOL

hadolint Dockerfile


--Optional: Static Analysis Using FindSecBugs--
wget https://github.com/WebGoat/WebGoat/releases/download/v8.1.0/webgoat-server-8.1.0.jar
java -h
apt update && apt install openjdk-8-jre -y
wget https://github.com/find-sec-bugs/find-sec-bugs/releases/download/version-1.9.0/findsecbugs-cli-1.9.0-fix2.zip && unzip findsecbugs-cli-1.9.0-fix2.zip -d /opt/
sed -i -e 's/\r$//' /opt/findsecbugs.sh
chmod +x /opt/findsecbugs.sh
export PATH=/opt/:$PATH
findsecbugs.sh -h
findsecbugs.sh -progress -html -output findsecbugs-report.html webgoat-server-8.1.0.jar


--Optional: Static Analysis Using SpotBugs--
wget https://github.com/spotbugs/spotbugs/releases/download/4.7.3/spotbugs-4.7.3.zip
unzip spotbugs-4.7.3.zip
echo -e "\nexport PATH=\$PATH:/spotbugs-4.7.3/bin" >> ~/.bashrc
source ~/.bashrc
chmod +x /spotbugs-4.7.3/bin/spotbugs
spotbugs -h
apt update && apt install default-jdk -y
git clone https://gitlab.practical-devsecops.training/pdso/android-java.git javaapp
cd javaapp
spotbugs -textui .
spotbugs -html -output spotbugs-output.html .
cd javaapp
python -m http.server 80
spotbugs -textui .
spotbugs -textui -quiet .
spotbugs -textui -progress .
spotbugs -textui -high .
spotbugs -textui -sortByClass .
spotbugs -textui -quiet -progress -high -sortByClass .


--Optional: Static Analysis Using njsscan--
git clone https://gitlab.practical-devsecops.training/pdso/nodejs.git webapp
cd webapp
pip3 install njsscan libsast
njsscan --help
njsscan --json -o output.json .
pip3 install njsscan libsast
cat output.json


--Optional: Code Quality Analysis With pylint--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install pylint
pylint --help
pylint taskManager/*.py
pylint taskManager/*.py -f json | tee output.json

cat > .pylintrc <<EOF
[MASTER]
disable=missing-module-docstring,import-error
EOF

pylint taskManager/*.py


--Optional: Code Quality Analysis With SonarQube--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
export SONAR_VERSION="4.7.0.2747"
wget https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-${SONAR_VERSION}-linux.zip -O /opt/sonar-scanner.zip
unzip /opt/sonar-scanner.zip -d /opt/
chmod +x /opt/sonar-scanner-${SONAR_VERSION}-linux/bin/sonar-scanner
export PATH=/opt/sonar-scanner-${SONAR_VERSION}-linux/bin/:$PATH
export SONARQUBE_TOKEN=INSERT_YOUR_TOKEN_HERE
sonar-scanner -Dsonar.projectKey=Django -Dsonar.sources=. -Dsonar.host.url=https://sonarqube-8lw53ql9.lab.practical-devsecops.training -Dsonar.login=$SONARQUBE_TOKEN


--Optional: Static Analysis Using PHPStan--
git clone https://gitlab.practical-devsecops.training/pdso/php.git
cd php
php -v
apt update && apt install composer -y
apt install php-xml -y
composer require --dev phpstan/phpstan
ls vendor/phpstan/phpstan
mv vendor/phpstan/phpstan/phpstan.phar /usr/local/bin/phpstan
phpstan --help
phpstan analyse .
phpstan analyse --error-format=json . | tee phpstan-output.json
cat phpstan-output.json | jq .


--Optional: How to Embed PHPStan into GitLab--
git clone https://gitlab.practical-devsecops.training/pdso/php.git
cd php
git remote rename origin old-origin
git remote add origin git@gitlab-ce-8lw53ql9:root/php.git
git push -u origin --all

image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - integration
  - prod

sast:
  stage: build
  script:
    # Download PHPStan docker container
    - docker pull phpstan/phpstan
    # Run docker container, please refer docker security course, if this doesn't make sense to you.
    - docker run -v $(pwd):/src --rm phpstan/phpstan analyse --error-format=json /src | tee phpstan-output.json
  artifacts:
    paths: [phpstan-output.json]
    when: always
  allow_failure: true   #<--- allow the build to fail but don't mark it as such

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: How To Embed SonarQube Scan Into GitHub Actions--
mkdir -p .github/workflows
cat >.github/workflows/main.yaml<<EOF
name: Django                                  # workflow name

on:
  push:                                       
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                    # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py check

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py test taskManager

  sonarqube:
    runs-on: ubuntu-20.04
    steps:
    - uses: actions/checkout@v2
      with:
        fetch-depth: 0

    - name: SonarQube Scan
      uses: sonarsource/sonarqube-scan-action@master
      env:
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
      with:
        projectBaseDir: .
        args: >
          -Dsonar.projectKey=Django

  integration:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."
EOF




----DAST (Dynamic Analysis) in CI/CD Pipeline----
#A technique to analyse running application for security vulnerabilities
#Maturity and Effectiveness (below)

#ZAP Proxy - 3/5 - web application vulnerability scanner, 2 scan types: ZAP Baseline, Full ZAP Scanner
	#Basline Scan good for CI/CD, runs 1 min spider, 1 min passive, low hanging fruits
	#Active Scan runs all tests from database, ideal for QA, deep scans
#Burp Suite - 4/5 - 
#Nikto - 3/5 - web server scanner, performs comprehensive tests
#SSLyze - 3/5 - SSL/TLS server scanning library for Python 2.7 and 3.4+, and CLI tool
#Nmap - 4/5 - network discovery and security auditing tool, has CLI, plugins, GUI Zenmap, packet gen tool Nping


--Dynamic Analysis using Nikto--
apt install -y libnet-ssleay-perl
git clone https://github.com/sullo/nikto
cd nikto/program
git checkout tags/2.1.6
#Run Nikto, can take a few minutes
./nikto.pl -output nikto_output.xml -h prod-8lw53ql9
cat nikto_output.xml

#SKIPIDS	Function: Allows skipping certain false-positive checks during the scan. Usage: Specify a comma-separated list of test ID numbers to skip. For example, exclude checks that consistently produce false positives for your target application.
#SKIPPORTS	Function: Specifies ports that Nikto will not scan, even if they are open. Usage: Provide a comma-separated list of ports to skip during the scan. For instance, exclude secure ports like 443 (HTTPS) if you don’t want to scan them.
#CLIOPTS	Function: Defines the command-line options to be used with Nikto. Usage: Customize Nikto’s behavior by specifying desired command-line options. For example, set output format, target host, and other scan-specific settings.
#STATIC-COOKIE	Function: Allows setting a static string as the Cookie: header in HTTP requests sent by Nikto. Usage: Set a static cookie value if required for authentication or accessing specific resources. Ensure Nikto includes this static cookie in its requests during the scan.
#TIMEOUT	Function: Sets the timeout value (in seconds) for HTTP requests made by Nikto. Usage: Adjust timeout based on network conditions and target server responsiveness. Longer timeouts may be necessary for slow or unreliable connections.
#EXTRAREQS	Function: Determines whether Nikto should use extra, non-normative HTTP methods to attempt revealing additional information or vulnerabilities. Usage: Set to 0 (disable) or 1 (enable). Enabling may reveal additional vulnerabilities but could increase scan time and trigger security alerts on the target server.

./nikto.pl -list-plugins
./nikto.pl -h prod-8lw53ql9 -Plugins headers

cat >/nikto/program/nikto.conf<<EOF
SKIPPORTS=21 22 111
CLIOPTS=-output result.csv -Format csv
EOF

./nikto.pl -h prod-8lw53ql9 -config nikto.conf


--Dynamic Analysis using SSLyze--
pip3 install sslyze==5.0.3
sslyze --help
sslyze --json_out sslyze-output.json prod-8lw53ql9.lab.practical-devsecops.training:443
cat sslyze-output.json


--Dynamic Analysis using Nmap--
apt-get update && apt-get install nmap -y
nmap -help
nmap prod-8lw53ql9 -oX nmap_out.xml
cat nmap_out.xml


--Embed Nikto, SSLyze, Nmap into CI/CD Pipeline--
*Build Docker Images in CI/CD Pipeline*
#Packages & Registeries -> Container Registry
build:
  stage: build
  before_script:
   - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY
  script:
   - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .  # Build the application into Docker image
   - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA        # Push the image into registry

*Deploy Application from CI/CD Pipeline*
#We need to add the following variables (Go to Project (django.nv) → Settings → CI/CD → Variables → Expand).
PROD_USERNAME		root
PROD_HOSTNAME		prod-8lw53ql9
PROD_SSH_PRIVKEY	Copy the private key from the production machine using SSH

ssh root@prod-8lw53ql9
more /root/.ssh/id_rsa

#Copy -----BEGIN RSA PRIVATE KEY----- * -----END RSA PRIVATE KEY-----

*The YAML file*
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - deploy
  - test

build:
  stage: build
  before_script:
   - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY
  script:
   - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .  # Build the application into Docker image
   - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA        # Push the image into registry

prod:
  stage: deploy
  image: kroniak/ssh-client:3.6
  environment: production
  needs:
    - build
  only:
    - main
  before_script:
   - mkdir -p ~/.ssh
   - echo "$PROD_SSH_PRIVKEY" > ~/.ssh/id_rsa
   - chmod 600 ~/.ssh/id_rsa
   - eval "$(ssh-agent -s)"
   - ssh-add ~/.ssh/id_rsa
   - ssh-keyscan -t rsa $PROD_HOSTNAME >> ~/.ssh/known_hosts
  script:
   - echo
   - |
      ssh $PROD_USERNAME@$PROD_HOSTNAME << EOF
        docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
        docker rm -f django.nv
        docker run -d --name django.nv -p 8000:8000 $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
      EOF

nikto:
  stage: test
  script:
    - docker pull hysnsec/nikto
    - docker run --rm -v $(pwd):/tmp hysnsec/nikto -h http://prod-8lw53ql9.lab.practical-devsecops.training -o /tmp/nikto-output.xml
  artifacts:
    paths: [nikto-output.xml]
    when: always
  allow_failure: true

sslscan:
  stage: test
  script:
    - docker pull hysnsec/sslyze
    - docker run --rm -v $(pwd):/tmp hysnsec/sslyze prod-8lw53ql9.lab.practical-devsecops.training:443 --json_out /tmp/sslyze-output.json
  artifacts:
    paths: [sslyze-output.json]
    when: always
  allow_failure: true

nmap:
  stage: test
  script:
    - docker pull hysnsec/nmap
    - docker run --rm -v $(pwd):/tmp hysnsec/nmap prod-8lw53ql9 -oX /tmp/nmap-output.xml
  artifacts:
    paths: [nmap-output.xml]
    when: always
  allow_failure: true


--Dynamic Analysis using ZAP--
docker pull softwaresecurityproject/zap-stable:2.13.0
docker run --rm softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py --help
docker run --rm softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training
docker run --user $(id -u):$(id -g) -w /zap -v $(pwd):/zap/wrk:rw --rm softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training -J zap-output.json

#The rw in the volume mount explicitly instructs the container to volume mount in read write mode. rw is optional to be used, but ZAP documentation recommends using rw as volume mount mode.
#The -w /zap instructs the container to set /zap as the working directory inside the container. The /zap working directory is required for the ZAP container to run a baseline scan.


--Embed ZAP into GitLab--
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

zap-baseline:
  stage: integration
  script:
    - docker pull softwaresecurityproject/zap-stable:2.13.0
    - docker run --user $(id -u):$(id -g) -w /zap -v $(pwd):/zap/wrk:rw --rm softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training -J zap-output.json
  after_script:
    - docker rmi softwaresecurityproject/zap-stable:2.13.0  # clean up the image to save the disk space
  artifacts:
    paths: [zap-output.json]
    when: always # What does this do?
  allow_failure: true


--Optional: Dynamic Analysis Using Dastardly--
docker pull public.ecr.aws/portswigger/dastardly
docker run --user $(id -u) --rm -v $(pwd):/dastardly -e BURP_START_URL=https://casp-pm-8lw53ql9.lab.practical-devsecops.training/apispec_1.json -e BURP_REPORT_FILE_PATH=/dastardly/dastardly-output.xml public.ecr.aws/portswigger/dastardly


--Optional: Dynamic Analysis Using Nuclei--
wget https://github.com/projectdiscovery/nuclei/releases/download/v2.9.6/nuclei_2.9.6_linux_amd64.zip
unzip nuclei_2.9.6_linux_amd64.zip
mv nuclei /usr/local/bin/nuclei
nuclei --help
nuclei -u https://prod-8lw53ql9.lab.practical-devsecops.training
nuclei -u https://prod-8lw53ql9.lab.practical-devsecops.training -j -o nuclei-output.json
cat nuclei-output.json | jq
git clone https://github.com/projectdiscovery/nuclei-templates.git && cd nuclei-templates
nuclei -u https://prod-8lw53ql9.lab.practical-devsecops.training -t http/misconfiguration/
docker pull projectdiscovery/nuclei:v2.9.6
cd /
rm nuclei-output.json && ls
docker run --user $(id -u):$(id -g) -w /nuclei -v $(pwd):/nuclei:rw --rm projectdiscovery/nuclei:v2.9.6 -u https://prod-8lw53ql9.lab.practical-devsecops.training -j -o nuclei-output.json
cat nuclei-output.json | jq


--Optional: How To Embed Zed Attack Proxy (ZAP) Into Jenkins--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    sh "docker run -u root -v \$(pwd):/zap/wrk:rw --rm -t softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training -J zap-output.json"
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'zap-output.json', fingerprint: true
                }
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'canceled')
        }
        always { 
            deleteDir()                     // clean up workspace
            dir("${WORKSPACE}@tmp") {       // clean up tmp directory
                deleteDir()
            }
            dir("${WORKSPACE}@script") {    // clean up script directory
                deleteDir()
            }
        }
    }
}


--Optional: How To Embed Zed Attack Proxy (ZAP) Into GitHub Actions--
cat >.github/workflows/main.yaml<<EOF
name: Django                                  # workflow name

on:
  push:                                       
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                    # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py check

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py test taskManager

  integration:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  zap_baseline:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - run: |
           docker pull softwaresecurityproject/zap-stable:2.13.0
           docker run --user root --rm -v $(pwd):/zap/wrk:rw -w /zap softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t ${{ secrets.PROD_URL }} -J zap-output.json
        continue-on-error: true

      - uses: actions/upload-artifact@v2
        with:
          name: ZAP Scan
          path: zap-output.json
        if: always()        # what is this for?

  zap_baseline2:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - name: Checkout
        uses: actions/checkout@v2
        with:
          ref: main

      - name: ZAP Scan
        uses: zaproxy/action-baseline@v0.4.0
        with:
          token: ${{ secrets.TOKEN }}
          docker_name: 'softwaresecurityproject/zap-stable:2.13.0'
          target: ${{ secrets.PROD_URL }}
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."
EOF


--Optional: How To Embed Zed Attack Proxy (ZAP) Into CircleCI--
cat >.circleci/config.yml<<EOF
jobs:
  build:
    docker:
      - image: python:3.6                   # similar to "image" in GitLab
    steps:
      - checkout
      - run: |                              # similar to "script" in GitLab
          pip install -r requirements.txt
          python manage.py check

  test:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: |
          pip install -r requirements.txt
          python manage.py test taskManager

  zap_baseline:
    machine: true
    steps:
      - checkout

      - run: |
          docker pull softwaresecurityproject/zap-stable:2.13.0
          docker run --user root --rm -v $(pwd):/zap/wrk:rw -w /zap softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t ${PROD_URL} -J zap-output.json || true

      - store_artifacts:
          path: zap-output.json
          destination: zap-artifact

  prod:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "This is a deploy step."

workflows:
  version: 2
  django:
    jobs:
      - build
      - test:
          requires:
            - build 
      - integration:
          requires:
            - test
      - prod:
          type: approval
          requires:
            - integration
EOF


--Optional: How To Embed Nuclei Into GitLab--
image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

nuclei:
  stage: integration
  script:
    - docker run --user $(id -u):$(id -g) -w /nuclei -v $(pwd):/nuclei:rw --rm projectdiscovery/nuclei:v2.9.6 -u https://prod-8lw53ql9.lab.practical-devsecops.training -j -o nuclei-output.json
  artifacts:
    paths: [nuclei-output.json]
    when: always # What does this do?
  allow_failure: true


--Optional: How To Embed Nuclei Into Jenkins--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    sh "docker run --user \$(id -u):\$(id -g) -w /nuclei -v \$(pwd):/nuclei:rw --rm projectdiscovery/nuclei:v2.9.6 -u https://prod-8lw53ql9.lab.practical-devsecops.training -j -o nuclei-output.json"
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'nuclei-output.json', fingerprint: true
                }
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'canceled')
        }
        always { 
            deleteDir()                     // clean up workspace
            dir("${WORKSPACE}@tmp") {       // clean up tmp directory
                deleteDir()
            }
            dir("${WORKSPACE}@script") {    // clean up script directory
                deleteDir()
            }
        }
    }
}


--Optional: How To Embed Nuclei Into GitHub Actions--
cat >.github/workflows/main.yaml<<EOF
name: Django                                  # workflow name

on:
  push:                                       
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                    # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py check

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py test taskManager

  nuclei-scan:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - run: |
           docker run --user $(id -u):$(id -g) -w /nuclei -v $(pwd):/nuclei:rw --rm projectdiscovery/nuclei:v2.9.6 -u https://prod-8lw53ql9.lab.practical-devsecops.training -j -o nuclei-output.json

      - uses: actions/upload-artifact@v2
        with:
          name: nuclei scan
          path: nuclei-output.json
        if: always()        # what is this for?

  nuclei-scan2:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - name: Checkout
        uses: actions/checkout@v2
        with:
          ref: main

      - name: Nuclei - Vulnerability Scan
        uses: projectdiscovery/nuclei-action@main
        with:
          target: ${{ secrets.PROD_URL }}
        continue-on-error: true

      - name: GitHub Workflow artifacts
        uses: actions/upload-artifact@v2
        with:
          name: nuclei.log
          path: nuclei.log    

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."
EOF


--Optional: How To Embed Nuclei Into CircleCI--
cat >.circleci/config.yml<<EOF
jobs:
  build:
    docker:
      - image: python:3.6                   # similar to "image" in GitLab
    steps:
      - checkout
      - run: |                              # similar to "script" in GitLab
          pip install -r requirements.txt
          python manage.py check

  test:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: |
          pip install -r requirements.txt
          python manage.py test taskManager

  nuclei:
    machine: true
    steps:
      - checkout

      - run: |
          docker run --user $(id -u):$(id -g) -w /nuclei -v $(pwd):/nuclei:rw --rm projectdiscovery/nuclei:v2.9.6 -u https://prod-8lw53ql9.lab.practical-devsecops.training -j -o nuclei-output.json

      - store_artifacts:
          path: nuclei-output.json
          destination: nuclei-artifact

  prod:
    docker:
      - image: python:3.6
    steps:
      - checkout
      - run: echo "This is a deploy step."

workflows:
  version: 2
  django:
    jobs:
      - build
      - test:
          requires:
            - build 
      - integration:
          requires:
            - test
      - prod:
          type: approval
          requires:
            - integration
EOF


--Optional: Hunting Vulnerability Using Nuclei--
wget https://github.com/projectdiscovery/nuclei/releases/download/v2.9.6/nuclei_2.9.6_linux_amd64.zip
unzip nuclei_2.9.6_linux_amd64.zip
mv nuclei /usr/local/bin/nuclei
nuclei --help
ssh root@sandbox-8lw53ql9
apt update && apt install -y nginx
git clone https://gitlab.practical-devsecops.training/pdso/vuln-api.git
cd vuln-api
docker build -t vuln-api .
docker run -d --name flask -p 5000:5000 vuln-api
curl localhost:5000

cat > /etc/nginx/sites-available/default<<EOF
server{
    listen      80;
    server_name sandbox-8lw53ql9.lab.practical-devsecops.training;

    access_log  /var/log/nginx/flask_access.log;
    error_log   /var/log/nginx/flask_error.log;

    proxy_buffers 16 64k;
    proxy_buffer_size 128k;

    location / {
        proxy_pass  http://localhost:5000;
        proxy_redirect off;

        proxy_set_header    Host            \$host;
        proxy_set_header    X-Real-IP       \$remote_addr;
        proxy_set_header    X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header    X-Forwarded-Proto http;
    }
}
EOF

systemctl restart nginx
exit

cat > http_header.yaml << EOF
id: http-header

info:
  name: HTTP Missing Security Headers
  author: Practical DevSecOps
  severity: medium
  tags: headers, http

requests:
  - method: GET
    path:
      - "{{BaseURL}}"

    host-redirects: true
    max-redirects: 3
    matchers-condition: or
    matchers:
      - type: word
        part: header
        words:
          - Set-Cookie
          - HttpOnly
        condition: and
        case-insensitive: true

      - type: dsl
        name: strict-transport-security
        dsl:
          - "!regex('(?i)strict-transport-security', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: content-security-policy
        dsl:
          - "!regex('(?i)content-security-policy', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: permissions-policy
        dsl:
          - "!regex('(?i)permissions-policy', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: x-frame-options
        dsl:
          - "!regex('(?i)x-frame-options', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: x-content-type-options
        dsl:
          - "!regex('(?i)x-content-type-options', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: x-permitted-cross-domain-policies
        dsl:
          - "!regex('(?i)x-permitted-cross-domain-policies', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: referrer-policy
        dsl:
          - "!regex('(?i)referrer-policy', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: clear-site-data
        dsl:
          - "!regex('(?i)clear-site-data', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: cross-origin-embedder-policy
        dsl:
          - "!regex('(?i)cross-origin-embedder-policy', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: cross-origin-opener-policy
        dsl:
          - "!regex('(?i)cross-origin-opener-policy', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: cross-origin-resource-policy
        dsl:
          - "!regex('(?i)cross-origin-resource-policy', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: access-control-allow-origin
        dsl:
          - "!regex('(?i)access-control-allow-origin', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: access-control-allow-credentials
        dsl:
          - "!regex('(?i)access-control-allow-credentials', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: access-control-expose-headers
        dsl:
          - "!regex('(?i)access-control-expose-headers', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: access-control-max-age
        dsl:
          - "!regex('(?i)access-control-max-age', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: access-control-allow-methods
        dsl:
          - "!regex('(?i)access-control-allow-methods', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and

      - type: dsl
        name: access-control-allow-headers
        dsl:
          - "!regex('(?i)access-control-allow-headers', all_headers)"
          - "status_code != 301 && status_code != 302"
        condition: and
EOF

nuclei -u https://sandbox-8lw53ql9.lab.practical-devsecops.training -t http_header.yaml
nuclei -u https://sandbox-8lw53ql9.lab.practical-devsecops.training -t http_header.yaml -j | jq

cat > sql-injection.yaml << EOF
id: sqli

info:
  name: SQL Injection
  author: Practical DevSecOps
  severity: High

requests:
  - method: GET

    path:
      - "{{BaseURL}} %22%22|0;#"
      - "{{BaseURL}} %22 OR 1 = 1 -- -#"
      - "{{BaseURL}} OR 1=1"
      - "{{BaseURL}} 1' ORDER BY 1,2,3--+"
      - "{{BaseURL}} 1' GROUP BY 1,2,3--+"

    extractors:
      - type: regex
        part: body
        regex:
          - "SQLite/JDBCDriver|SQLite.Exception|System.Data.SQLite.SQLiteException|Warning.*sqlite_.*|Warning.*SQLite3::|SQLITE_ERROR|sqlite3.*|\\\[|null"
EOF

nuclei -u https://sandbox-8lw53ql9.lab.practical-devsecops.training/api/v1/resources/todos/ -t sql-injection.yaml
nuclei -u https://sandbox-8lw53ql9.lab.practical-devsecops.training/api/v1/resources/todos/ -t sql-injection.yaml -j | jq


--Optional: Identifying More Targets Using Katana--
wget https://github.com/projectdiscovery/katana/releases/download/v1.0.3/katana_1.0.3_linux_amd64.zip
unzip katana_1.0.3_linux_amd64.zip
mv katana /usr/bin/
katana --help
katana -u https://prod-8lw53ql9.lab.practical-devsecops.training/


--Optional: Fuzzing Using Nuclei--
wget https://github.com/projectdiscovery/nuclei/releases/download/v2.9.12/nuclei_2.9.12_linux_amd64.zip
unzip nuclei_2.9.12_linux_amd64.zip
mv nuclei /usr/bin/
nuclei
nuclei --help
wget https://github.com/projectdiscovery/katana/releases/download/v1.0.3/katana_1.0.3_linux_amd64.zip
unzip katana_1.0.3_linux_amd64.zip
mv katana /usr/bin/
katana --help
katana -u https://public-firing-range.appspot.com/ -f qurl
katana -u https://public-firing-range.appspot.com/ -f qurl -o endpoints.txt
sed -i '/^$/d' endpoints.txt
git clone https://github.com/projectdiscovery/fuzzing-templates.git
nuclei -list endpoints.txt -t fuzzing-templates
nuclei -list endpoints.txt -t fuzzing-templates -verbose


--Optional: Using Nuclei Workflows for DAST Scanning--
wget https://github.com/projectdiscovery/nuclei/releases/download/v2.9.12/nuclei_2.9.12_linux_amd64.zip
unzip nuclei_2.9.12_linux_amd64.zip
mv nuclei /usr/bin/
nuclei
nuclei --help

cat > django-workflow.yaml << EOF
id: my-custom-workflow

info:
  name: Django workflow
  author: pdso

workflows:
  - template: http/technologies/tech-detect.yaml
    matchers:
      - name: nginx
        subtemplates:
          - template: http/exposed-panels/django-admin-panel.yaml
          - template: http/misconfiguration/django-debug-detect.yaml
          - template: http/technologies/default-django-page.yaml
          - template: http/exposures/files/django-secret-key.yaml
          - template: http/exposures/configs/django-variables-exposed.yaml
          - template: http/exposures/logs/django-debug-exposure.yaml
          - template: file/logs/django-framework-exceptions.yaml
EOF

nuclei -w django-workflow.yaml -validate
nuclei -u https://prod-8lw53ql9.lab.practical-devsecops.training/ -w django-workflow.yaml
nuclei -u https://prod-8lw53ql9.lab.practical-devsecops.training/ -w django-workflow.yaml -v
time nuclei -u https://prod-8lw53ql9.lab.practical-devsecops.training/ -w django-workflow.yaml
time nuclei -u https://prod-8lw53ql9.lab.practical-devsecops.training/ -t /root/nuclei-templates/




----Infrastructure as Code (IaC) and its Security----
#Technique to create, manage, and destroy infrastructure as if its code by applying software development practices.
#This makes infrastructure managed as repeatable, testable, reusable and self-documenting.

*Benefits*
#Self service - on demand
#On-demand and Programmable - managed on demand and automated via API
#Confidence and Reliability - automation and rollback
#Continous Integration/Improvement - version controlled, continous testing with CI/CD

*Problems it Solves*
#Configuration Drift - systems drift apart and behave differently due to differemt configurations
#Lack of trust in automation - operations lacks confidence in automation
#Untouchable systems - config drift, manual changes, legacy systems, lack of attention
#Erosion - kernel updates, package updates, etc leads to system erosion

#On-Demand Platform - AWS, GCP, Azure, etc
#Infrastructure Definition - Terraform, Cloud formation, CFengine, etc
#Configuration Tools - Ansible, Chef, Puppet, Packer, Salt, etc

#Ansible - simplest way to automate apps and IT infrastructure
*Components of Ansible*
#Modules - Executable code(libraries) which run on target nodes, backbone of Ansible
#Tasks & Roles - Smallest executable entities, roles lets you group multiple tasks, variables, etc
#Playbooks - Contains instructions to execute on node to allow configuration of system
#Inventory - A list of servers/systems to manage, can be grouped in many ways


--Hardening using Ansible--
pip3 install ansible==8.7.0 ansible-lint==6.8.1

cat > inventory.ini <<EOL

# DevSecOps Studio Inventory
[devsecops]
devsecops-box-8lw53ql9

[prod]
prod-8lw53ql9

EOL

ssh-keyscan -t rsa prod-8lw53ql9 >> ~/.ssh/known_hosts
ssh-keyscan -t rsa devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts
ssh-keyscan -t rsa prod-8lw53ql9 devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts

ansible -i inventory.ini  prod -m apt -a "name=ntp state=present"
ansible -i inventory.ini all -m command -a "bash --version"

ansible-doc -l | grep shell
ansible -i inventory.ini prod -m shell -a "uptime"

cat > playbook.yml <<EOL
---
- name: Example playbook to install firewalld
  hosts: prod
  remote_user: root
  become: yes
  gather_facts: no
  vars:
    state: present

  tasks:
  - name: ensure firewalld is at the latest version
    apt:
      name: firewalld
      update_cache: yes
EOL

ansible-playbook -i inventory.ini playbook.yml

#Create a new directory /challenge and create a playbook.yml file inside the /challenge directory. You can use the above playbook.yml syntax as a starter for this task, but the /challenge/playbook.yml needs to use the secfigo.terraform role to install the Terraform utility.
mkdir /challenge && cd /challenge
cp ../inventory.ini .

cat > /challenge/playbook.yml <<EOL
---
- name: Example playbook to install Terraform using ansible role.
  hosts: prod
  remote_user: root
  become: yes

  roles:
    - secfigo.terraform
EOL

#Install secfigo.terraform role using ansible-galaxy.
ansible-galaxy install secfigo.terraform

#Execute the /challenge/playbook.yml against the prod machine to install the Terraform utility. Optionally put this hardening job in the CI pipeline.
ansible-playbook -i /challenge/inventory.ini /challenge/playbook.yml

#This step 5 is repeated from previous step 4 challange, not sure, will document anyway.
ansible-galaxy role --help
#Please press q to get out of the editor.
ansible-galaxy search terraform
ansible-galaxy install secfigo.terraform

cat > /challenge/playbook.yml <<EOL
---
- name: Example playbook to install Terraform using ansible role.
  hosts: prod
  remote_user: root
  become: yes

  roles:
    - secfigo.terraform
EOL

ansible-playbook -i /challenge/inventory.ini /challenge/playbook.yml

#Create a new directory /hardening and create an ansible-hardening.yml file inside the /hardening directory. The /hardening/ansible-hardening.yml needs to use the dev-sec.os-hardening role to harden a target server.
mkdir /hardening && cd /hardening
cp ../inventory.ini .

cat > /hardening/ansible-hardening.yml <<EOL
---
- name: Playbook to harden Ubuntu OS.
  hosts: prod
  remote_user: root
  become: yes

  roles:
    - dev-sec.os-hardening

EOL

#Install dev-sec.os-hardening role from ansible-galaxy
ansible-galaxy install dev-sec.os-hardening

#Execute the /hardening/ansible-hardening.yml to harden the Ubuntu production machine. Optionally put this hardening job in the CI pipeline.
ansible-playbook -i /hardening/inventory.ini /hardening/ansible-hardening.yml


--Ansible Ad Hoc Commands--
pip3 install ansible==8.7.0

cat > inventory.ini <<EOL

[devsecops]
devsecops-box-8lw53ql9

[sandbox]
sandbox-8lw53ql9

[prod]
prod-8lw53ql9

EOL

ansible -i inventory.ini prod --list-hosts
ansible -i inventory.ini gitlab --list-hosts

ansible --version
mkdir /etc/ansible/

cat > /etc/ansible/ansible.cfg <<EOF
[defaults]
stdout_callback = yaml
deprecation_warnings = False
host_key_checking = False
retry_files_enabled = False
inventory = /inventory.ini
EOF

ansible --version

ssh-keyscan -t rsa devsecops-box-8lw53ql9 sandbox-8lw53ql9 prod-8lw53ql9 >> ~/.ssh/known_hosts
ansible -i inventory.ini all -m ping
ansible -i inventory.ini all -m shell -a "hostname"
ansible -i inventory.ini all -m apt -a "name=ntp"
ansible-doc -l | egrep "add_host|amazon.aws.aws"

#Use the ansible-doc command to see help examples and find a module that can send a file from DevSecOps-Box to remote machines
ansible-doc -h

#Create a file with some content, let the file name be notes at the location /root
echo "test" > /root/notes

#Using an ansible ad-hoc command, copy the file /root/notes into all remote machines (sandbox and production) to the destination directory /root
ansible -i inventory.ini all -m copy -a "src=/root/notes dest=/root"


--Harden Machines in CI/CD Pipelines--
pip3 install ansible==8.7.0

cat > inventory.ini <<EOL

# DevSecOps Studio Inventory
[devsecops]
devsecops-box-8lw53ql9

[gitservers]
gitlab-ce-8lw53ql9

[prod]
prod-8lw53ql9
EOL

ssh-keyscan -t rsa prod-8lw53ql9 >> ~/.ssh/known_hosts
ssh-keyscan -t rsa gitlab-ce-8lw53ql9 >> ~/.ssh/known_hosts
ssh-keyscan -t rsa devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts

ssh-keyscan -t rsa prod-8lw53ql9 gitlab-ce-8lw53ql9 devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts

ansible-galaxy install dev-sec.os-hardening

cat > ansible-hardening.yml <<EOL
---
- name: Playbook to harden Ubuntu OS.
  hosts: prod
  remote_user: root
  become: yes

  roles:
    - dev-sec.os-hardening

EOL

ansible-playbook -i inventory.ini ansible-hardening.yml

#Add the variables to the project, Settings, CI/CD, Variables
DEPLOYMENT_SERVER				prod-8lw53ql9
DEPLOYMENT_SERVER_SSH_PRIVKEY	Copy the private key from the production machine using SSH. The SSH key is available at /root/.ssh/id_rsa. Please refer to Advanced Linux Exercises for a refresher on SSH Keys
more /root/.ssh/id_rsa

#Add to YAML file
ansible-hardening:
  stage: prod
  image: willhallonline/ansible:2.9-ubuntu-18.04
  before_script:
    - mkdir -p ~/.ssh
    - echo "$DEPLOYMENT_SERVER_SSH_PRIVKEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval "$(ssh-agent -s)"
    - ssh-add ~/.ssh/id_rsa
    - ssh-keyscan -t rsa $DEPLOYMENT_SERVER >> ~/.ssh/known_hosts
  script:
    - echo -e "[prod]\n$DEPLOYMENT_SERVER" >> inventory.ini
    - ansible-galaxy install dev-sec.os-hardening
    - ansible-playbook -i inventory.ini ansible-hardening.yml

#Create this file in the repo "ansible-hardening.yml"
---
- name: Playbook to harden ubuntu OS.
  hosts: prod
  remote_user: root
  become: yes

  roles:
    - dev-sec.os-hardening


--Optional: Working With Ansible Playbook--
pip3 install ansible==8.7.0

cat > inventory.ini <<EOL

# DevSecOps Studio Inventory
[devsecops]
devsecops-box-8lw53ql9

[sandbox]
sandbox-8lw53ql9

EOL

ssh-keyscan -t rsa devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts
ssh-keyscan -t rsa sandbox-8lw53ql9 >> ~/.ssh/known_hosts
ssh-keyscan -t rsa sandbox-8lw53ql9 devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts
mkdir simple-playbook && cd simple-playbook
mkdir tasks

cat > tasks/main.yml <<EOL
---
- name: Install nginx
  apt:
    name: nginx
    state: present
    update_cache: true

- name: Copy the configuration
  template:
    src: templates/default.j2
    dest: /etc/nginx/sites-enabled/default

- name: Start nginx service
  service:
    name: nginx
    state: started
    enabled: yes

- name: Clone django repository
  git:
    repo: https://gitlab.practical-devsecops.training/pdso/django.nv.git
    dest: /opt/django

- name: Install dependencies
  command: pip3 install -r requirements.txt
  args:
    chdir: /opt/django

- name: Database migration
  command: python3 manage.py migrate
  args:
    chdir: /opt/django

- name: Load data from the fixtures
  shell: python3 manage.py loaddata fixtures/*
  args:
    chdir: /opt/django

- name: Run an application in the background
  shell: nohup python3 manage.py runserver 0.0.0.0:8000 &
  args:
    chdir: /opt/django
EOL

mkdir templates

cat > templates/default.j2 <<EOL
{% raw %}
server {
    listen      80;
    server_name localhost;

    access_log  /var/log/nginx/django_access.log;
    error_log   /var/log/nginx/django_error.log;

    proxy_buffers 16 64k;
    proxy_buffer_size 128k;

    location / {
        proxy_pass  http://localhost:8000;
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
        proxy_redirect off;

        proxy_set_header    Host \$host;
        proxy_set_header    X-Real-IP \$remote_addr;
        proxy_set_header    X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header    X-Forwarded-Proto http;
    }
}
{% endraw %}
EOL

cat > main.yml <<EOL
---
- name: Simple playbook
  hosts: sandbox
  remote_user: root
  gather_facts: no

  tasks:
  - include: tasks/main.yml
EOL

tree
ansible-playbook -i inventory.ini main.yml
mv ../inventory.ini .
ansible-playbook -i inventory.ini main.yml
ssh sandbox-8lw53ql9
which nginx
netstat -tlpn
exit
curl sandbox-8lw53ql9


--Optional: Ansible Conditionals--
pip3 install ansible==8.7.0

cat > inventory.ini <<EOL
# DevSecOps Studio Inventory
[devsecops]
devsecops-box-8lw53ql9

[sandbox]
sandbox-8lw53ql9
EOL

ssh-keyscan -t rsa sandbox-8lw53ql9 >> ~/.ssh/known_hosts
ssh-keyscan -t rsa devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts
ssh-keyscan -t rsa sandbox-8lw53ql9 devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts
mkdir myplaybook && cd myplaybook
pwd

cat > main.yml <<EOL
---
- name: Simple playbook
  hosts: all
  remote_user: root
  gather_facts: yes     # what does it means?

  tasks:
  - debug:
      msg: "This system uses Ubuntu-based distro"
    when: ansible_distribution == "Ubuntu"
EOL

ansible -i inventory.ini all -m setup
ansible-playbook -i inventory.ini main.yml
ls
cp -r /inventory.ini inventory.ini
ansible-playbook -i inventory.ini main.yml

cat > main.yml <<EOL
---
- name: Simple playbook
  hosts: all
  remote_user: root
  gather_facts: yes     # what does it mean?

  tasks:
  - debug:
      msg: "This system is used CentOS-based distro"
    when: ansible_distribution == "CentOS"
EOL

ansible-playbook -i inventory.ini main.yml

cat > main.yml <<EOL
---
- name: Simple playbook
  hosts: all
  remote_user: root
  gather_facts: no     # what does it mean?

  tasks:
  - name: Show the content of /etc/os-release
    command: cat /etc/os-release
    register: os_release

  - debug:
      msg: "This system uses Ubuntu-based distro"
    when: os_release.stdout.find('Ubuntu') != -1
EOL

ansible-playbook -i inventory.ini main.yml
cd /

#Challenge #1 - Create a new playbook file at /challenges/main.yml that contains a task to check if the nginx package is installed or not using stat module
mkdir /challenges
cp -r /inventory.ini /challenges/inventory.ini

cat > /challenges/main.yml <<EOL
- name: Playbook to install nginx
  hosts: all
  remote_user: root
  become: yes

  # We are checking availability of nginx binary at a specific location
  tasks:
    - name: check if nginx installed
      stat:
        path: /usr/sbin/nginx
      register: stat_nginx
EOL

ansible-playbook -i /challenges/inventory.ini /challenges/main.yml
#OR
cd /challenges
ansible-playbook -i inventory.ini main.yml

#Challenge #2 - Add another task with name Print version to print the nginx version by using the msg module if nginx is installed
cat > /challenges/main.yml <<EOL
- name: Playbook to install nginx
  hosts: all
  remote_user: root
  become: yes

  # We are checking availability of nginx binary at a specific location
  tasks:
    - name: check if nginx installed
      stat:
        path: /usr/sbin/nginx
      register: stat_nginx

    - name: get nginx version
      command: nginx -v
      register: nginx_version
      when: stat_nginx.stat.exists

    - name: Print version
      debug:
        msg: "{{ nginx_version.stderr }}"
      when:
        - nginx_version is defined
        - stat_nginx.stat.exists
EOL

ansible-playbook -i /challenges/inventory.ini /challenges/main.yml

#Challenge #3 - Otherwise, let your playbook install the missing nginx using the apt module in the sandbox machine
cat > /challenges/main.yml <<EOL
- name: Playbook to install nginx
  hosts: sandbox
  remote_user: root
  become: yes

  # We are checking availability of nginx binary at a specific location
  tasks:
    - name: check if nginx installed
      stat:
        path: /usr/sbin/nginx
      register: stat_nginx

    - name: get nginx version
      command: nginx -v
      register: nginx_version
      when: stat_nginx.stat.exists

    - name: Print version
      debug:
        msg: "{{ nginx_version.stderr }}"
      when:
        - nginx_version is defined
        - stat_nginx.stat.exists

    - name: install nginx if not exist
      apt:
        name: nginx
        state: present
        update_cache: true
      when: not stat_nginx.stat.exists
EOL

ansible-playbook -i /challenges/inventory.ini /challenges/main.yml


--Optional: Deploying Docker Container Using Ansible--
pip3 install ansible==8.7.0
mkdir ~/playbook

cat > ~/playbook/inventory.ini <<EOF
[devsecops-box]
devsecops-box-8lw53ql9

[prod]
prod-8lw53ql9 ansible_python_interpreter=/usr/bin/python3
EOF

ssh-keyscan -t rsa prod-8lw53ql9 devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts
ansible -i ~/playbook/inventory.ini prod -m shell -a "docker version"
cd ~/
git clone https://gitlab.practical-devsecops.training/pdso/django.nv.git ~/django.nv
cd ~/django.nv
docker build -t registry-8lw53ql9.lab.practical-devsecops.training/django.nv:1.0 .
docker push registry-8lw53ql9.lab.practical-devsecops.training/django.nv:1.0
echo "pdso-training" | docker login --username root --password-stdin registry-8lw53ql9.lab.practical-devsecops.training
cd ~/
cd ~/playbook

cat >main.yml <<EOL
---
- name: Deploying container
  hosts: prod
  remote_user: root
  gather_facts: no

  tasks:
  - name: Ensure docker is installed
    stat:
      path: "/usr/bin/docker"
    register: docker_result

  - debug:
      msg: "Please install the docker"
    when: not docker_result.stat.exists

  - name: Log into DockerHub
    docker_login:
      registry_url: "registry-8lw53ql9.lab.practical-devsecops.training"
      username: "{{ docker_username }}"
      password: "{{ docker_password }}"

  - name: Pulling new image
    docker_image:
      name: "registry-8lw53ql9.lab.practical-devsecops.training/django.nv:1.0"
      source: pull

  - name: Remove django.nv container
    docker_container:
      name: "django.nv"
      state: absent
      force_kill: yes

  - name: Running new container
    docker_container:
      name: "django.nv"
      image: "registry-8lw53ql9.lab.practical-devsecops.training/django.nv:1.0"
      detach: yes
      ports:
        - 8000:8000
EOL

ansible-playbook -i inventory.ini -e "docker_username=root docker_password=pdso-training" main.yml
#Let’s install the necessary Python library by adding a tasks in main.yml file.
  - name: Install python-docker for Docker SDK
    pip:
      name: docker
      executable: pip

pip install docker

cat >main.yml <<EOL
---
- name: Deploying container
  hosts: prod
  remote_user: root
  gather_facts: no

  tasks:
  - name: Ensure docker is installed
    stat:
      path: "/usr/bin/docker"
    register: docker_result

  - debug:
      msg: "Please install the docker"
    when: not docker_result.stat.exists

  - name: Install python3-docker for Docker SDK
    pip:
      name: docker
      executable: pip3

  - name: Log into DockerHub
    docker_login:
      registry_url: "registry-8lw53ql9.lab.practical-devsecops.training"
      username: "{{ docker_username }}"
      password: "{{ docker_password }}"

  - name: Pulling new image
    docker_image:
      name: "registry-8lw53ql9.lab.practical-devsecops.training/django.nv:1.0"
      source: pull

  - name: Remove django.nv container
    docker_container:
      name: "django.nv"
      state: absent
      force_kill: yes

  - name: Running new container
    docker_container:
      name: "django.nv"
      image: "registry-8lw53ql9.lab.practical-devsecops.training/django.nv:1.0"
      detach: yes
      ports:
        - 8000:8000
EOL

ansible-playbook -i inventory.ini -e "docker_username=root docker_password=pdso-training" main.yml
ansible -i inventory.ini prod -m shell -a "docker ps"


--Optional: How To Embed Ansible Into Jenkins CI/CD Pipeline--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step"
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
        stage("ansible-hardening"){
            agent {
                docker {
                    image 'willhallonline/ansible:2.13-ubuntu-20.04'
                    args '-u root'
                }
            }
            steps {
                sshagent(['ssh-prod']) {
                    withCredentials([string(credentialsId: 'prod-server', variable: 'DEPLOYMENT_SERVER')]) {
                        sh """
                        mkdir ~/.ssh
                        ssh-keyscan -t rsa $DEPLOYMENT_SERVER >> ~/.ssh/known_hosts
                        echo "[prod]\n$DEPLOYMENT_SERVER" >> inventory.ini
                        ansible-galaxy install dev-sec.os-hardening
                        ansible-playbook -i inventory.ini ansible-hardening.yml
                        """
                    }
                }
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'canceled')
        }
        always { 
            deleteDir()                     // clean up workspace
            dir("${WORKSPACE}@tmp") {       // clean up tmp directory
                deleteDir()
            }
            dir("${WORKSPACE}@script") {    // clean up script directory
                deleteDir()
            }
        }
    }
}

#That makes sense. We didn’t upload the ansible-hardening.yml to the git repository.
---
- name: Playbook to harden the Ubuntu OS.
  hosts: prod
  remote_user: root
  become: yes

  roles:
    - dev-sec.os-hardening


--Optional: Use TFLint To Find Security Issues in IaC--
curl https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh | bash
git clone https://gitlab.practical-devsecops.training/pdso/terraform.git
cd terraform
tflint -h
tflint --chdir=aws


--Optional: How To Embed TFLint Into GitHub Actions--
cat >.github/workflows/main.yaml<<EOF
name: Terraform                               # workflow name

on:
  push:                                       
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  tflint:
    runs-on: ubuntu-20.04
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - uses: terraform-linters/setup-tflint@v1
        name: Setup TFLint
        with:
          tflint_version: latest

      - name: Run TFLint
        run: tflint --chdir=aws -f json > tflint-output.json
        continue-on-error: true

      - uses: actions/upload-artifact@v2
        with:
          name: TFLint
          path: tflint-output.json
        if: always()                        # what is this for?

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - run: echo "This is a test step"

  integration:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step"
EOF


--Optional: How To Embed TFLint Into CircleCI--
jobs:
  tflint:
    machine: true
    steps:
      - checkout

      - run: 
          command: docker run --rm -v $(pwd):/data -t ghcr.io/terraform-linters/tflint --chdir=aws -f json | tee tflint-output.json || true

      - store_artifacts:
          path: tflint-output.json
          destination: tflint-artifact
          when: always

  test:
    machine: true
    steps:
      - checkout
      - run: echo "This is a test step"

  integration:
    machine: true
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1

  prod:
    machine: true
    steps:
      - checkout
      - run: echo "This is a deploy step"

workflows:
  version: 2
  terraform:
    jobs:
      - tflint
      - test:
          requires:
            - tflint
      - integration:
          requires:
            - test
      - prod:
          type: approval
          requires:
            - integration


--Optional: Use Checkov To Check Misconfigurations in IaC--
pip3 install checkov==2.3.22
git clone https://gitlab.practical-devsecops.training/pdso/terraform.git
checkov -h
checkov -f terraform/aws/s3.tf
checkov -d terraform/aws
checkov -d /terraform/ -o json > /terraform/scan-result.json
jq ".[0].summary.failed" /terraform/scan-result.json
checkov -d /terraform/ -o json --skip-check CKV_AWS_18,CKV_AWS_21,CKV_AWS_20,CKV_AWS_52,CKV_AWS_19 > /terraform/scan-result-skipped.json


--Optional: How To Embed Checkov Into CI/CD Pipeline--
git clone https://gitlab.practical-devsecops.training/pdso/terraform.git terraform
cd terraform
git remote rename origin old-origin
git remote add origin git@gitlab-ce-8lw53ql9:root/terraform.git
git push -u origin --all

image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - validate
  - build
  - test
  - release
  - preprod
  - integration
  - prod

checkov:
  stage: validate
  script:
    - docker pull bridgecrew/checkov
    - docker run --rm -w /src -v $(pwd):/src bridgecrew/checkov -d aws -o json | tee checkov-output.json
  artifacts:
    paths: [checkov-output.json]
    when: always
  allow_failure: true

test:
  stage: test
  script:
    - echo "This is a test step"

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: How To Embed Checkov Into Jenkins CI/CD Pipeline--
git clone https://gitlab.practical-devsecops.training/pdso/terraform.git terraform
cd terraform
git remote rename origin old-origin
git remote add origin http://gitlab-ce-8lw53ql9.lab.practical-devsecops.training/root/terraform.git
git checkout -b main
git push -u origin main

pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("checkov") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    sh "docker run --rm -w /src -v \$(pwd):/src bridgecrew/checkov -d aws -o json | tee checkov-output.json"
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'checkov-output.json', fingerprint: true
                }
            }
        }
        stage("test") {
            steps {
                echo "This is a test step."
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step."
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'skipped')
        }
        always {
            deleteDir()                     // clean up workspace
        }
    }
}


--Optional: How To Embed Checkov Into CircleCI--
jobs:
  build:
    machine: true
    steps:
      - checkout
      - run: echo "This is a build step"

  test:
    machine: true
    steps:
      - checkout
      - run: echo "This is a test step"

  checkov:
    machine: true
    steps:
      - checkout

      - run: 
          command: docker run --rm -w /src -v $(pwd):/src bridgecrew/checkov -d aws -o json | tee checkov-output.json || true

      - store_artifacts:
          path: checkov-output.json
          destination: checkov-artifact
          when: always

  integration:
    machine: true
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: on_fail         # Even if the job fails, continue to the next stages

  prod:
    machine: true
    steps:
      - checkout
      - run: echo "This is a deploy step"

workflows:
  version: 2
  terraform:
    jobs:
      - checkov
      - test:
          requires:
            - checkov
      - integration:
          requires:
            - test
      - prod:
          type: approval
          requires:
            - integration


--Optional: Secure IaC Using Ansible Vault--
pip3 install ansible==8.7.0

cat > inventory.ini <<EOL

# DevSecOps Studio Inventory
[devsecops]
devsecops-box-8lw53ql9

[prod]
prod-8lw53ql9

EOL

ssh-keyscan -t rsa prod-8lw53ql9 >> ~/.ssh/known_hosts
ssh-keyscan -t rsa devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts
ssh-keyscan -t rsa prod-8lw53ql9 devsecops-box-8lw53ql9 >> ~/.ssh/known_hosts
ansible -i inventory.ini prod -m shell -a "uptime"
echo "hello" > example
ansible -i inventory.ini prod -m copy -a "src=example dest=/example"
ssh root@prod-8lw53ql9
ls /
exit
echo "StrongP@ssw0rd" > /secret
ansible-vault encrypt /secret --ask-vault-pass
cat /secret
ansible -i inventory.ini prod --ask-vault-pass -m copy -a "src=/secret dest=/secret"
ssh root@prod-8lw53ql9 "cat /secret"


--Optional: Use Terrascan To Find Security Issues in IaC--
wget https://github.com/accurics/terrascan/releases/download/v1.12.0/terrascan_1.12.0_Linux_x86_64.tar.gz
tar -xvf terrascan_1.12.0_Linux_x86_64.tar.gz
chmod +x terrascan
mv terrascan /usr/local/bin/
git clone https://gitlab.practical-devsecops.training/pdso/terraform.git
cd terraform
terrascan -h
terrascan scan -d gcp
terrascan scan -d gcp --severity high


--Optional: How To Embed Terrascan Into CI/CD Pipeline--
git clone https://gitlab.practical-devsecops.training/pdso/terraform.git terraform
cd terraform
git remote rename origin old-origin
git remote add origin git@gitlab-ce-8lw53ql9:root/terraform.git
git push -u origin --all

image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - validate
  - build
  - test
  - release
  - preprod
  - integration
  - prod

terrascan:
  stage: validate
  image:
    name: accurics/terrascan:latest
    entrypoint: ["/bin/sh", "-c"]
  script:
    - /go/bin/terrascan scan . -o json > terrascan-output.json
  artifacts:
    paths: [terrascan-output.json]
    when: always
  allow_failure: true

test:
  stage: test
  script:
    - echo "This is a test step"

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: How To Embed Terrascan Into GitHub Actions--
cat >.github/workflows/main.yaml<<EOF
name: Terraform                               # workflow name

on:
  push:                                       
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  terrascan:
    runs-on: ubuntu-20.04
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Run Terrascan
        id: terrascan
        uses: accurics/terrascan-action@v1
        with:
          iac_type: 'terraform'
          iac_version: 'v14'
          policy_type: 'aws'
          only_warn: true
          iac_dir: 'aws'

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - run: echo "This is a test step"

  integration:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step"
EOF


--Optional: How To Embed Terrascan Into CircleCI--
cat >.circleci/config.yml<<EOF
jobs:
  terrascan:
    machine: true
    steps:
      - checkout

      - run: 
          command: docker run --rm -v $(pwd):/src accurics/terrascan scan -t aws -d /src/aws -o json | tee terrascan-output.json || true

      - store_artifacts:
          path: terrascan-output.json
          destination: terrascan-artifact
          when: always

  test:
    machine: true
    steps:
      - checkout
      - run: echo "This is a test step"

  integration:
    machine: true
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: on_fail         # Even if the job fails, continue to the next stages

  prod:
    machine: true
    steps:
      - checkout
      - run: echo "This is a deploy step"

workflows:
  version: 2
  terraform:
    jobs:
      - terrascan
      - test:
          requires:
            - terrascan
      - integration:
          requires:
            - test
      - prod:
          type: approval
          requires:
            - integration
EOF


--Optional: Use tfsec To Find Security Issues in IaC--
wget -O /usr/local/bin/tfsec https://github.com/aquasecurity/tfsec/releases/download/v0.55.0/tfsec-linux-amd64
chmod +x /usr/local/bin/tfsec
git clone https://gitlab.practical-devsecops.training/pdso/terraform.git
cd terraform
tfsec -h
tfsec aws
tfsec aws -f json | tee tfsec-output.json


--Optional: How To Embed tfsec Into CI/CD Pipeline--
git clone https://gitlab.practical-devsecops.training/pdso/terraform.git terraform
cd terraform
git remote rename origin old-origin
git remote add origin git@gitlab-ce-8lw53ql9:root/terraform.git
git push -u origin --all

image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - validate
  - build
  - test
  - release
  - preprod
  - integration
  - prod

tfsec:
  stage: validate
  script:
    - docker run --rm -v $(pwd):/src aquasec/tfsec /src -f json | tee tfsec-output.json
  artifacts:
    paths: [tfsec-output.json]
    when: always
  allow_failure: true

test:
  stage: test
  script:
    - echo "This is a test step"

integration:
  stage: integration
  script:
    - echo "This is an integration step"
    - exit 1
  allow_failure: true # Even if the job fails, continue to the next stages

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
  when: manual # Continuous Delivery


--Optional: How To Embed tfsec Into GitHub Actions--
cat >.github/workflows/main.yaml<<EOF
name: Terraform                               # workflow name

on:
  push:                                       
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  tfsec:
    runs-on: ubuntu-20.04
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Terraform security scan
        uses: aquasecurity/tfsec-action@v1.0.0
        with:
          soft_fail: true

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - run: echo "This is a test step"

  integration:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step"
EOF


--Optional: How To Embed tfsec Into CircleCI--
jobs:
  tfsec:
    machine: true
    steps:
      - checkout

      - run:
          command: docker run --rm -v $(pwd):/src aquasec/tfsec /src -f json | tee tfsec-output.json || true

      - store_artifacts:
          path: tfsec-output.json
          destination: tfsec-artifact
          when: always

  test:
    machine: true
    steps:
      - checkout
      - run: echo "This is a test step"

  integration:
    machine: true
    steps:
      - checkout
      - run:
          command: |
            echo "This is an integration step"
            exit 1
          when: on_fail         # Even if the job fails, continue to the next stages

  prod:
    machine: true
    steps:
      - checkout
      - run: echo "This is a deploy step"

workflows:
  version: 2
  terraform:
    jobs:
      - tfsec
      - test:
          requires:
            - tfsec
      - integration:
          requires:
            - test
      - prod:
          type: approval
          requires:
            - integration


--Optional: Use Snyk Tool To Find Security Issues in Your IaC--
git clone https://gitlab.practical-devsecops.training/pdso/terraform
cd terraform
wget -O /usr/local/bin/snyk https://github.com/snyk/cli/releases/download/v1.1105.0/snyk-linux
chmod +x /usr/local/bin/snyk
snyk iac --help
snyk iac test aws --json
snyk auth YOUR_API_TOKEN_HERE
export SNYK_TOKEN=YOUR_TOKEN_HERE
snyk iac test aws --json > snyk-output.json


--Optional: Securing IaC Using KICS--
git clone https://gitlab.practical-devsecops.training/pdso/terraform
cd terraform
docker pull checkmarx/kics:v1.7.11
docker run -t -v $(pwd):/path checkmarx/kics:v1.7.11 --help
pwd #/terraform
docker run -t -v $(pwd):/path checkmarx/kics:v1.7.11 scan
docker run -t -v $(pwd):/path checkmarx/kics:v1.7.11 scan --path "/path"
docker run -t -v $(pwd):/path checkmarx/kics:v1.7.11 scan --path "/path" --output-path "/path" --report-formats html
cd terraform
python -m http.server 80




----Compliance as Code (CaC)----
#Many organizations do security to be compliant with regulations
#Use InSpec, open source testing framework for infrastructure, auditing framework
#Ease of Use, Automation, OS and App Support, Extensible Language
#There is also OpenSCAP and Ansible for compliance


--Compliance as Code (CaC) using InSpec--
wget https://packages.chef.io/files/stable/inspec/5.22.29/ubuntu/18.04/inspec_5.22.29-1_amd64.deb
dpkg -i inspec_5.22.29-1_amd64.deb
inspec --help

#This command prevents the ssh agent from prompting YES or NO question.
echo "StrictHostKeyChecking accept-new" >> ~/.ssh/config

inspec exec https://github.com/dev-sec/linux-baseline.git -t ssh://root@prod-8lw53ql9 -i ~/.ssh/id_rsa --chef-license accept

DEPLOYMENT_SERVER				prod-8lw53ql9
DEPLOYMENT_SERVER_SSH_PRIVKEY	Copy the private key from the prod machine using SSH. The SSH key is available at /root/.ssh/id_rsa
more /root/.ssh/id_rsa

#Use hysnsec/inspec docker image to perform continuous compliance scanning with https://github.com/dev-sec/linux-baseline profile and embed it as part of the prod stage with job name as inspec
#The job should only be triggered when changes are pushed to the main branch (don’t use rules attribute)
#Save the output as JSON file at /share/inspec-output.json and upload it using artifacts attribute
inspec:
  stage: prod
  only:
    - main
  environment: production
  before_script:
    - mkdir -p ~/.ssh
    - echo "$DEPLOYMENT_SERVER_SSH_PRIVKEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval "$(ssh-agent -s)"
    - ssh-add ~/.ssh/id_rsa
    - ssh-keyscan -t rsa $DEPLOYMENT_SERVER >> ~/.ssh/known_hosts
  script:
    - docker run --rm -v ~/.ssh:/root/.ssh -v $(pwd):/share hysnsec/inspec exec https://github.com/dev-sec/linux-baseline.git -t ssh://root@$DEPLOYMENT_SERVER -i ~/.ssh/id_rsa --chef-license accept --reporter json:/share/inspec-output.json
  artifacts:
    paths: [inspec-output.json]
    when: always


--How to Create Custom InSpec Profile--
curl https://omnitruck.chef.io/install.sh | sudo bash -s -- -v 5.22.29 -P inspec
inspec --help

mkdir inspec-profile && cd inspec-profile
inspec init profile ubuntu --chef-license accept

cat > ubuntu/controls/example.rb <<EOL
describe file('/etc/shadow') do
    it { should exist }
    it { should be_file }
    it { should be_owned_by 'root' }
  end
EOL

inspec check ubuntu
inspec exec ubuntu

echo "StrictHostKeyChecking accept-new" >> ~/.ssh/config
inspec exec ubuntu -t ssh://root@prod-8lw53ql9 -i ~/.ssh/id_rsa --chef-license accept

#Use inspec init to create a new inspec profile with name challenge under /inspec-profile directory
cd /inspec-profile
inspec init profile challenge --chef-license accept

#Edit our newly created Inspec skeleton to add four basic checks (system, password, ssh, and useradd) from PCI/DSS requirements
cat > /inspec-profile/challenge/controls/example.rb <<EOL
describe file('/etc/pam.d/system-auth') do
    its('content') { 
        should match(/^\s*password\s+requisite\s+pam_pwquality\.so\s+(\S+\s+)*try_first_pass/)
    }
    its('content') {
        should match(/^\s*password\s+requisite\s+pam_pwquality\.so\s+(\S+\s+)*retry=[3210]/)
    }
end

describe file('/etc/pam.d/password-auth') do
    its('content') { 
        should match(/^\s*password\s+requisite\s+pam_pwquality\.so\s+(\S+\s+)*try_first_pass/)
    }
    its('content') {
        should match(/^\s*password\s+requisite\s+pam_pwquality\.so\s+(\S+\s+)*retry=[3210]/)
    }
end

describe file('/etc/default/useradd') do
    its('content') {
        should match(/^\s*INACTIVE\s*=\s*(30|[1-2][0-9]|[1-9])\s*(\s+#.*)?$/)
    }
end

describe file('/etc/ssh/sshd_config') do
    it { should exist }
    it { should be_file }
    it { should be_owned_by 'root' }
    its('content') { should match 'PasswordAuthentication no' }
end
EOL

#Run the tests locally before setting it up in the CI pipeline
inspec check challenge
inspec exec challenge

#Commit the inspec profile to the project’s repository using either the GitLab UI or Git commands
cd
pwd
git clone git@gitlab-ce-8lw53ql9:root/django-nv.git
cd django-nv
cp -r /inspec-profile/challenge challenge
git add challenge
git config --global user.email "you@example.com"
git config --global user.name "Your Name"
git commit -m "Add custom inspec profile"
git push origin main

#Add a new job named compliance in the test stage within the .gitlab-ci.yml file to check and execute the profile using the inspec command
#Option 1
image: docker:20.10

services:
  - docker:dind

stages:
  - test

compliance:
  stage: test
  script:
    - docker run -i --rm -v $(pwd):/share chef/inspec check challenge --chef-license accept
    - docker run -i --rm -v $(pwd):/share chef/inspec exec challenge --chef-license accept
  allow_failure: true

#Option 2
cat >.gitlab-ci.yml<<EOF
image: docker:20.10

services:
  - docker:dind

stages:
  - test

compliance:
  stage: test
  script:
    - docker run -i --rm -v $(pwd):/share chef/inspec check challenge --chef-license accept
    - docker run -i --rm -v $(pwd):/share chef/inspec exec challenge --chef-license accept
  allow_failure: true
EOF

git add .gitlab-ci.yml
git commit -m "Update .gitlab-ci.yml"
git push origin main

#Which file is commonly used to define controls within a custom InSpec profile?
#controls.rb


--Optional: InSpec Shell--
curl https://omnitruck.chef.io/install.sh | sudo bash -s -- -v 5.22.29 -P inspec
inspec --help
echo "StrictHostKeyChecking accept-new" >> ~/.ssh/config
inspec shell -t ssh://root@prod-8lw53ql9 -i ~/.ssh/id_rsa --chef-license accept
help
help resources
file('/tmp').class.superclass.instance_methods(false).sort
file('/tmp').directory?
file('/tmp').exist?
file('/tmp').content

describe file('/tmp') do
it { should be_directory }
end

os_env('PATH')
os_env('PATH').content
os_env('PATH').split
exit


--Optional: InSpec Command Resources--
curl https://omnitruck.chef.io/install.sh | sudo bash -s -- -v 5.22.29 -P inspec
mkdir cis-ubuntu
cd cis-ubuntu
inspec init profile ubuntu --chef-license accept
grep -Ei "^\s*Defaults\s+([^#]+,\s*)?use_pty(,\s+\S+\s*)*(\s+#.*)?$" /etc/sudoers /etc/sudoers.d/*

cat >> /etc/sudoers <<EOL
#
# This file MUST be edited with the 'visudo' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
Defaults        env_reset
Defaults        mail_badpass
Defaults        secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin"
Defaults        use_pty    # you can put it here
# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root    ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo   ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "#include" directives:

#includedir /etc/sudoers.d
EOL

grep -Ei "^\s*Defaults\s+([^#]+,\s*)?use_pty(,\s+\S+\s*)*(\s+#.*)?$" /etc/sudoers /etc/sudoers.d/*

cat > ubuntu/controls/example.rb <<EOL
control 'ubuntu-1.3.2' do
   title 'Ensure sudo commands use pty'
   desc 'Attackers can run a malicious program using sudo, which would again fork a background process that remains even when the main program has finished executing.'
   describe command('grep -Ei "^\s*Defaults\s+([^#]+,\s*)?use_pty(,\s+\S+\s*)*(\s+#.*)?$" /etc/sudoers /etc/sudoers.d/*') do
      its('stdout') { should match /Defaults(\s*)use_pty/ }
   end
end
EOL

inspec check ubuntu
inspec exec ubuntu
echo "StrictHostKeyChecking accept-new" >> ~/.ssh/config
inspec exec ubuntu -t ssh://root@prod-8lw53ql9 -i ~/.ssh/id_rsa --chef-license accept


--Optional: InSpec File Resource--
curl https://omnitruck.chef.io/install.sh | sudo bash -s -- -v 5.22.29 -P inspec
mkdir cis-ubuntu
cd cis-ubuntu
inspec init profile ubuntu --chef-license accept
grep -Ei "^\s*Defaults\s+([^#]+,\s*)?use_pty(,\s+\S+\s*)*(\s+#.*)?$" /etc/sudoers /etc/sudoers.d/*

cat >> /etc/sudoers <<EOL
#
# This file MUST be edited with the 'visudo' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
Defaults        env_reset
Defaults        mail_badpass
Defaults        secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin"
Defaults        use_pty    # you can put it here
# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root    ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo   ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "#include" directives:

#includedir /etc/sudoers.d
EOL

grep -Ei "^\s*Defaults\s+([^#]+,\s*)?use_pty(,\s+\S+\s*)*(\s+#.*)?$" /etc/sudoers /etc/sudoers.d/*

cat > ubuntu/controls/example.rb <<EOL
control 'ubuntu-1.3.2' do
   title 'Ensure sudo commands use pty'
   desc 'Attackers can run a malicious program using sudo, which would again fork a background process that remains even when the main program has finished executing.'
   describe file('/etc/sudoers') do
      its('content') { should match /Defaults(\s*)use_pty/ }
   end
end
EOL

inspec check ubuntu
inspec exec ubuntu
echo "StrictHostKeyChecking accept-new" >> ~/.ssh/config
inspec exec ubuntu -t ssh://root@prod-8lw53ql9 -i ~/.ssh/id_rsa --chef-license accept


--Optional: InSpec Custom Matchers--
curl https://omnitruck.chef.io/install.sh | sudo bash -s -- -v 5.22.29 -P inspec
mkdir cis-ubuntu
cd cis-ubuntu
inspec init profile ubuntu --chef-license accept
stat /etc/ssh/sshd_config
chown root:root /etc/ssh/sshd_config
chmod og-rwx /etc/ssh/sshd_config

cat > ubuntu/controls/example.rb <<EOL
control 'ubuntu-5.2.1' do
   title 'Ensure permissions on /etc/ssh/sshd_config are configured'
   desc 'The /etc/ssh/sshd_configfile contains configuration specifications for sshd. The command below checks whether the owner and group of the file is root.'
   describe file('/etc/ssh/sshd_config') do
     its('owner') { should eq 'root'}
     its('group') { should eq 'root'}
     its('mode') { should cmp '0600' }
   end
end
EOL

inspec check ubuntu
inspec exec ubuntu
echo "StrictHostKeyChecking accept-new" >> ~/.ssh/config
inspec exec ubuntu -t ssh://root@prod-8lw53ql9 -i ~/.ssh/id_rsa --chef-license accept


--Optional: InSpec Dependencies--
wget https://packages.chef.io/files/stable/inspec/5.22.29/ubuntu/18.04/inspec_5.22.29-1_amd64.deb
dpkg -i inspec_5.22.29-1_amd64.deb
mkdir cis-ubuntu
cd cis-ubuntu
inspec init profile ubuntu --chef-license accept
rm ubuntu/inspec.yml

cat >> ubuntu/inspec.yml <<EOL
name: profile-dependency
title: Profile with Dependencies
maintainer: InSpec Authors
copyright: InSpec Authors
copyright_email: support@chef.io
license: Apache-2.0
summary: InSpec Profile that is only consuming dependencies
version: 0.2.0
depends:
  - name: SSH baseline
    url: https://github.com/dev-sec/ssh-baseline/archive/master.tar.gz
  - name: Linux Baseline
    url: https://github.com/dev-sec/linux-baseline/archive/master.tar.gz
EOL

cd ubuntu
inspec vendor
cd ..
echo "StrictHostKeyChecking accept-new" >> ~/.ssh/config

cat >> ubuntu/controls/example.rb << EOL
# copyright: 2018, The Authors

title "sample section"

# you can also use plain tests
describe file("/tmp") do
  it { should be_directory }
end

# you add controls here
control "tmp-1.0" do                        # A unique ID for this control
  impact 0.7                                # The criticality, if this control fails.
  title "Create /tmp directory"             # A human-readable title
  desc "An optional description..."
  describe file("/tmp") do                  # The actual test
    it { should be_directory }
  end
end

include_controls 'SSH baseline'
include_controls 'Linux Baseline'
EOL

inspec exec ubuntu -t ssh://root@prod-8lw53ql9 -i ~/.ssh/id_rsa --chef-license accept


--Optional: Create InSpec Profile for CIS Benchmark--
curl https://omnitruck.chef.io/install.sh | sudo bash -s -- -v 5.22.29 -P inspec
inspec --help
mkdir cis-ubuntu && cd cis-ubuntu
inspec init profile ubuntu --chef-license accept

cat >> ubuntu/controls/configure_sudo.rb <<EOL
control 'ubuntu-1.3.1' do
   title 'Ensure sudo is installed'
   desc 'sudo allows a permitted user to execute a command as the superuser or another user, as specified by the security policy.'
   describe package('sudo') do
      it { should be_installed }
   end
end

control 'ubuntu-1.3.2' do
   title 'Ensure sudo commands use pty'
   desc 'Attackers can run a malicious program using sudo, which would again fork a background process that remains even when the main program has finished executing.'
   describe command('grep -Ei "^\s*Defaults\s+([^#]+,\s*)?use_pty(,\s+\S+\s*)*(\s+#.*)?$" /etc/sudoers').stdout do
      it { should include 'Defaults use_pty' }
   end
end

control 'ubuntu-1.3.3' do
   title 'Ensure sudo log file exists'
   desc 'Attackers can run a malicious program using sudo, which would again fork a background process that remains even when the main program has finished executing.'
   describe command('grep -Ei "^\s*Defaults\s+logfile=\S+" /etc/sudoers').stdout do
      it { should include 'Defaults logfile=' }
   end
end
EOL

rm ubuntu/controls/example.rb
inspec check ubuntu
inspec exec ubuntu
echo "StrictHostKeyChecking accept-new" >> ~/.ssh/config
inspec exec ubuntu -t ssh://root@prod-8lw53ql9 -i ~/.ssh/id_rsa --chef-license accept

#Once you edit the /etc/sudoers file, it should look like the following output
~# cat /etc/sudoers
# This file MUST be edited with the 'visudo' command as root.
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
# See the man page for details on how to write a sudoers file.
Defaults        env_reset
Defaults        mail_badpass
Defaults        secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin"
Defaults use_pty
Defaults logfile="/var/log/sudo.log"


--Optional: InSpec With ASVS Controls--
curl https://omnitruck.chef.io/install.sh | sudo bash -s -- -v 5.22.29 -P inspec
mkdir inspec-asvs
cd inspec-asvs
inspec init profile asvs --chef-license accept

cat > asvs/controls/example.rb <<EOL
control 'ASVS-14.4.1' do
    impact 0.7
    title 'Safe character set'
    desc 'HTTP response contains content type header with safe character set'
    describe http('https://prod-8lw53ql9.lab.practical-devsecops.training') do
        its ('headers.Content-type') { should cmp 'text/html; charset=utf-8'}
    end
end

control 'ASVS-14.4.2' do
    impact 0.7
    title 'Contain Content Disposition header attachment'
    desc "Add Content-Disposition header to the server's configuration, Add 'attachment' directive to the header."
    describe http('https://prod-8lw53ql9.lab.practical-devsecops.training') do
        its ('headers.content-disposition') { should cmp 'attachment' }
    end
end

control 'ASVS-14.4.3' do
    impact 0.7
    title 'Content Security Policy Options != none / contain unsafe-inline;unsafe-eval;\* '
    desc "Ensure that CSP is not configured with the directives: 'unsafe-inline', 'unsafe-eval' and wildcards."
    describe http('https://prod-8lw53ql9.lab.practical-devsecops.training') do
        its ('headers.content-security-policy') { should_not cmp 'none' }
        its ('headers.content-security-policy') { should_not include 'unsafe-inline;unsafe-eval;\*'}
    end
end

control 'ASVS-14.4.4' do
    impact 0.7
    title 'Content type Options = no sniff'
    desc 'All responses should contain X-Content-Type-Options=nosniff'
    describe http('https://prod-8lw53ql9.lab.practical-devsecops.training') do
        its ('headers.x-content-type-options') { should cmp 'nosniff'}
    end
end

control 'ASVS-14.4.5' do
    impact 0.7
    title 'HSTS is using directives max-age=15724800'
    desc 'Verify that HTTP Strict Transport Security headers are included on all responses and for all subdomains, such as Strict-Transport-Security: max-age=15724800; includeSubDomains.'
    describe http('https://prod-8lw53ql9.lab.practical-devsecops.training') do
        its ('headers.Strict-Transport-Security') { should match /\d/ }
    end
end

control 'ASVS-14.4.6' do
    impact 0.7
    title "'Referrer-Policy' header is included"
    desc "HTTP requests may include Referrer header, which may expose sensitive information. Referrer-Policy restiricts how much information is sent in the Referer header."
    describe http('https://prod-8lw53ql9.lab.practical-devsecops.training') do
        its ('headers.referrer-policy') { should cmp 'no-referrer; same-origin' }
    end
end
EOL

inspec check asvs
inspec exec asvs


--Optional: Docker Compliance Using InSpec--
curl https://omnitruck.chef.io/install.sh | sudo bash -s -- -v 5.22.29 -P inspec
inspec --help
mkdir inspec && cd inspec
inspec exec https://github.com/dev-sec/cis-docker-benchmark.git --chef-license accept
docker run -d --name alpine -it alpine /bin/sh
docker ps
inspec exec https://github.com/dev-sec/linux-baseline.git --chef-license accept -t docker://alpine
inspec exec https://github.com/dev-sec/cis-docker-benchmark.git --chef-license accept


--Optional: How To Embed InSpec Into Jenkins--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step."
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
        stage("Inspec"){
            agent {
                docker {
                    image 'hysnsec/inspec'
                    args '-u root'
                }
            }
            steps {
                sshagent(['ssh-prod']) {
                    catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {     // Allow the sast stage to fail
                        sh "inspec exec https://github.com/dev-sec/linux-baseline.git -t ssh://root@prod-8lw53ql9 --chef-license accept --reporter json:inspec-output.json"
                    }
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'inspec-output.json', fingerprint: true
                }
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: STAGE_NAME, state: 'skipped')
        }
        always { 
            deleteDir()                     // clean up workspace
        }
    }
}




----Vulnerability Management with Central Tools----
#Defect Dojo, a security program and vulnerability management tool.
#Manages app security, schedule scans, triage vulnerabilities, defect trackers, etc
#Web application, integrates to many security applications and scanners seen in course.
#https://defectdojo.github.io/django-DefectDojo/
#Alternatives: ThreadFix, RSA Archer GRC


--Working with DefectDojo--
git clone https://gitlab.practical-devsecops.training/pdso/rails.git webapp
cd webapp
docker run --rm -v $(pwd):/src hysnsec/brakeman -f json /src | tee brakeman-result.json

#We will start by creating a Product first. In the sidebar, click on Add Product and fill the forms with the following information.
#Name					Rails
#Description			Web Application based on Rails framework
#Product Type			Web Application
#Business criticality	Medium
#Platform				Web

#In this product we can’t upload any scan report because there is no engagement, lets create an engagement by clicking on Engagements in the menu and selecting Add New Interactive Engagement.
#Name			SAST Scan
#Description	SAST activities
#Target start	You can pick any custom date as the engagement start date
#Target end		You can pick any custom date as the engagement end date
#Status			In Progress
#Product		Rails

curl https://gitlab.practical-devsecops.training/-/snippets/3/raw -o upload-results.py
pip3 install requests
python3 upload-results.py --help

#We need to provide the following inputs for the upload-results.py script to work.
#HOST			https://dojo-8lw53ql9.lab.practical-devsecops.training
#USERNAME		root
#API_KEY		Find it at https://dojo-8lw53ql9.lab.practical-devsecops.training/api/key-v2
#ENGAGEMENT_ID	ID of the engagement, here its 1
#PRODUCT_ID		ID of product, here its 1
#LEAD_ID		ID of the user conducting the testing
#ENVIRONMENT:	Environment name
#SCANNER		Name of the scanner, this is case sensitive e.g., ZAP Scan, Bandit Scan, etc
#RESULT_FILE	The path to the tool’s output

#Use the following command to get an API key through curl, and save the API key as an environment variable API_KEY.
export API_KEY=$(curl -s -XPOST -H 'content-type: application/json' https://dojo-8lw53ql9.lab.practical-devsecops.training/api/v2/api-token-auth/ -d '{"username": "root", "password": "pdso-training"}' | jq -r '.token' )
echo $API_KEY

#We can now upload the brakeman’s scan output (brakeman-result.json) to DefectDojo.
python3 upload-results.py --host dojo-8lw53ql9.lab.practical-devsecops.training --api_key $API_KEY --engagement_id 2 --product_id 3 --lead_id 1 --environment "Production" --result_file brakeman-result.json --scanner "Brakeman Scan"


--Vulnerability Management with DefectDojo--
git clone https://gitlab.practical-devsecops.training/pdso/django.nv webapp
cd webapp
pip3 install bandit==1.7.1
bandit -r . -f json | tee bandit-output.json

curl https://gitlab.practical-devsecops.training/-/snippets/3/raw -o upload-results.py
python3 upload-results.py --help

export API_KEY=INSERT_API_KEY_HERE
#OR
export API_KEY=$(curl -s -XPOST -H 'content-type: application/json' https://dojo-8lw53ql9.lab.practical-devsecops.training/api/v2/api-token-auth/ -d '{"username": "root", "password": "pdso-training"}' | jq -r '.token' )
echo $API_KEY

python3 upload-results.py --host dojo-8lw53ql9.lab.practical-devsecops.training --api_key $API_KEY --engagement_id 1 --product_id 1 --lead_id 1 --environment "Production" --result_file bandit-output.json --scanner "Bandit Scan"

#Scan the production machine https://prod-8lw53ql9.lab.practical-devsecops.training with the help of the ZAP docker image softwaresecurityproject/zap-stable:2.13.0, and save the results to /webapp/zap-output.xml
#Refer to the exercise How to Embed Zed Attack Proxy (ZAP) into GitLab, with output set to xml format -d -x zap-output.xml
docker run --user $(id -u):$(id -g) -w /zap -v $(pwd):/zap/wrk:rw \
           --rm softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py \
           -t https://prod-8lw53ql9.lab.practical-devsecops.training \
           -d -x zap-output.xml

#Upload the ZAP scan results to Defect Dojo
python3 upload-results.py --host dojo-8lw53ql9.lab.practical-devsecops.training \
    --api_key $API_KEY --engagement_id 1 --product_id 1 \
    --lead_id 1 --environment "Production" \
    --result_file /webapp/zap-output.xml \
    --scanner "ZAP Scan"


--Automated Results Upload in GitLab--
#Note: We’ve discussed different methods of using the tool:
#Native Installation:			Directly installing the tool on the system.
#Package Manager or Binary:		Installing via a package manager or using the binary file.
#Docker:						Running the tool within a Docker container.

#In summary:
#All methods are suitable for CI/CD integration.
#Docker is recommended for CI/CD as it operates smoothly without dependencies.
#Using the binary file is efficient, avoiding additional dependencies.
#Ultimately, you can choose either method based on your specific situation.

#We need to set DOJO_HOST and DOJO_API_TOKEN under secrets variables by visiting the following URL
DOJO_HOST			dojo-8lw53ql9.lab.practical-devsecops.training
DOJO_API_TOKEN		#Copy from https://dojo-8lw53ql9.lab.practical-devsecops.training/api/key-v2

image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

sast:
  stage: build
  before_script:
    - apk add py-pip py-requests
  script:
    - docker pull hysnsec/bandit  # Download bandit docker container
    - docker run --user $(id -u):$(id -g) -v $(pwd):/src --rm hysnsec/bandit -r /src -f json -o /src/bandit-output.json
  after_script:
    - python3 upload-results.py --host $DOJO_HOST --api_key $DOJO_API_TOKEN --engagement_id 1 --product_id 1 --lead_id 1 --environment "Production" --result_file bandit-output.json --scanner "Bandit Scan"
  artifacts:
    paths: [bandit-output.json]
    when: always

integration:
  stage: integration
  script:
    - echo "This is an integration step"

prod:
  stage: prod
  script:
    - echo "This is a deploy step."


git config --global user.email "student@pdevsecops.com"
git config --global user.name "student"

git clone git@gitlab-ce-8lw53ql9:root/django-nv.git
cd django-nv
curl https://gitlab.practical-devsecops.training/-/snippets/3/raw -o upload-results.py
git add upload-results.py
git commit -m "Add upload-results.py file"
git push origin main

#Use the terminal provided on the right to scan the production machine https://prod-8lw53ql9.lab.practical-devsecops.training in DevSecOps Box with the help of the ZAP docker image softwaresecurityproject/zap-stable:2.13.0 and save the result at /django-nv/zap-output.xml
docker run --user $(id -u):$(id -g) -w /zap -v $(pwd):/zap/wrk:rw --rm softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training -d -x zap-output.xml

#After you store the ZAP scan results, please upload the result manually to Defect Dojo using the terminal on the right
export API_KEY=$(curl -s -XPOST -H 'content-type: application/json' https://dojo-8lw53ql9.lab.practical-devsecops.training/api/v2/api-token-auth/ -d '{"username": "root", "password": "pdso-training"}' | jq -r '.token' )
python3 upload-results.py --host dojo-8lw53ql9.lab.practical-devsecops.training --api_key $API_KEY --engagement_id 1 --product_id 1 --lead_id 1 --environment "Production" --result_file zap-output.xml --scanner "ZAP Scan"

#Please update the .gitlab-ci.yml file and add the upload-results.py as part of the ZAP Scan in the CI/CD pipeline inside the after_script attribute
#Add the below example dast-zap job in .gitlab-ci.yml
#Ensure you set appropriate environment variables in the CI/CD system before trying the below solution.
dast-zap:
  stage: integration
  before_script:
    - apk add py-pip py-requests
    - docker pull softwaresecurityproject/zap-stable:2.13.0
  script:
    - docker run --user $(id -u):$(id -g) -w /zap -v $(pwd):/zap/wrk:rw --rm softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training -d -x zap-output.xml
  after_script:
    - python3 upload-results.py --host $DOJO_HOST --api_key $DOJO_API_TOKEN --engagement_id 1 --product_id 1 --lead_id 1 --environment "Production" --result_file zap-output.xml --scanner "ZAP Scan"
  artifacts:
    paths: [zap-output.xml]
    when: always
    expire_in: 1 day


--Optional: Automated Results Upload in Jenkins CI/CD Pipeline--
pipeline {
    agent any

    options {
        gitLabConnection('gitlab')
    }

    stages {
        stage("build") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py check
                """
            }
        }
        stage("test") {
            agent {
                docker {
                    image 'python:3.6'
                    args '-u root'
                }
            }
            steps {
                sh """
                pip3 install --user virtualenv
                python3 -m virtualenv env
                . env/bin/activate
                pip3 install -r requirements.txt
                python3 manage.py test taskManager
                """
            }
        }
        stage("sast") {
            steps {
                withCredentials([string(credentialsId: 'dojo-host', variable: 'DOJO_HOST'), string(credentialsId: 'dojo-api-token', variable: 'DOJO_API_TOKEN')]) {
                    sh """
                    docker run -v \$(pwd):/src --rm hysnsec/bandit -r /src -f json -o /src/bandit-output.json || true       # ignore exit code 1, because the next command doesn't execute when the previous command failed
                    python3 upload-results.py --host $DOJO_HOST --api_key $DOJO_API_TOKEN --engagement_id 1 --product_id 1 --lead_id 1 --environment "Production" --result_file bandit-output.json --scanner 'Bandit Scan'
                    """
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'bandit-output.json', fingerprint: true
                }
            }
        }
        stage("integration") {
            steps {
                catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                    echo "This is an integration step."
                    sh "exit 1"
                }
            }
        }
        stage("prod") {
            steps {
                input "Deploy to production?"
                echo "This is a deploy step."
            }
        }
    }
    post {
        failure {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        unstable {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'failed')
        }
        success {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'success')
        }
        aborted {
            updateGitlabCommitStatus(name: "\${env.STAGE_NAME}", state: 'canceled')
        }
        always { 
            deleteDir()                     // clean up workspace
            dir("${WORKSPACE}@tmp") {       // clean up tmp directory
                deleteDir()
            }
            dir("${WORKSPACE}@script") {    // clean up script directory
                deleteDir()
            }
        }
    }
}

#Before we commit this file to the repository, we need to set DOJO_HOST and DOJO_API_TOKEN variables as we do not want the credentials to be hardcoded in the Jenkinsfile. Let’s add the creds to the Jenkins credential store by visiting https://jenkins-8lw53ql9.lab.practical-devsecops.training/credentials/store/system/domain/_/.
#Click on the Add Credentials link on the left sidebar, then select Secret text as Kind, and add the following credentials into it.
#Credentials	
#Secret:	dojo-8lw53ql9.lab.practical-devsecops.training
#ID:	dojo-host
#Add another credential with the same Kind.
#Credentials	
#Secret:	Find it at https://dojo-8lw53ql9.lab.practical-devsecops.training/api/key-v2
#ID:	dojo-api-token
#You need to log into the dojo website using the following credentials to fetch the API Key.
#Machine Details	
#URL	dojo-8lw53ql9.lab.practical-devsecops.training/api/key-v2
#Username	root
#Password	pdso-training

git clone git@gitlab-ce-8lw53ql9:root/django-nv.git
cd django-nv
curl https://gitlab.practical-devsecops.training/-/snippets/3/raw -o upload-results.py
git add upload-results.py
git commit -m "Add upload-results.py file"
git push origin main


--Optional: Automated Results Upload in GitHub Actions--
cat >.github/workflows/main.yaml<<EOF
name: Django                                  # workflow name

on:
  push:
    branches:                                 # similar to "only" in GitLab
      - main

jobs:
  build:
    runs-on: ubuntu-20.04                    # similar to "image" in GitLab
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py check

  test:
    runs-on: ubuntu-20.04
    needs: build
    steps:
      - uses: actions/checkout@v2

      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: |
          pip3 install --upgrade virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          python manage.py test taskManager

  sast:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - uses: actions/checkout@v2

      - run: docker run --rm -v $(pwd):/src hysnsec/bandit -r /src -f json -o /src/bandit-output.json

      - uses: actions/upload-artifact@v2
        with:
          name: Bandit
          path: bandit-output.json
        if: always()                        # what is this for?

      - uses: actions/setup-python@v2
        with:
          python-version: '3.6'

      - run: python3 upload-results.py --host ${{ secrets.DOJO_HOST }} --api_key ${{ secrets.DOJO_API_TOKEN }} --engagement_id 1 --product_id 1 --lead_id 1 --environment "Production" --result_file bandit-output.json --scanner "Bandit Scan"

  integration:
    runs-on: ubuntu-20.04
    needs: test
    steps:
      - run: echo "This is an integration step"
      - run: exit 1
        continue-on-error: true

  prod:
    runs-on: ubuntu-20.04
    needs: integration
    steps:
      - run: echo "This is a deploy step."
EOF

#Before we commit this file to the repository, We need to set DOJO_HOST and DOJO_API_TOKEN using secrets in our repository. To set up a secret, go back to django.nv repository and click the Settings tab.
#Click the Secrets option, then select New repository secret and add the following credentials into it.
#Name	Value
#Key	DOJO_HOST
#Value	dojo-8lw53ql9.lab.practical-devsecops.training
#Name	Value
#Key	DOJO_API_TOKEN
#Value	Find it at https://dojo-8lw53ql9.lab.practical-devsecops.training/api/key-v2
#Once done, click the Add secret button.
#You also need to log into the dojo website using the following credentials to fetch the API Key.
#Name	Value
#URL	dojo-8lw53ql9.lab.practical-devsecops.training/api/key-v2
#Username	root
#Password	pdso-training
#Once you’re done with the variables, you can commit the .github/workflows/main.yaml file, and push the changes to GitHub.

curl https://gitlab.practical-devsecops.training/-/snippets/3/raw -o upload-results.py
git add upload-results.py
git commit -m "Add upload-results.py file"
git push origin main




----Summary and Conclusion----
--Optional: A Full Enterprise Grade DevSecOps Pipelines--
#In this scenario, you will learn to tie SCA, SAST, DAST, IaC, CaC scans and Vulnerability Management aspects of the DevSecOps Together.
#Of course, you will be embedding the above practices in the CI/CD pipeline to create a full fledged DevSecOps Pipeline.

#Note: You would need to set appropriate environment variables under Gitlab’s CI/CD variables to get the following tasks to work.
#Also you would need to push ansible-hardening.yml and inspec profiles etc., to the git repository as discussed under Infrastructure as Coce(IaC) and Compliance as Code(CaC) modules.
#Make sure you have added the necessary variables into your project (Settings > CI/CD) such as $DOJO_HOST, and $DOJO_API_TOKEN. Otherwise, your results are not uploaded to DefectDojo in the sast-with-vm job.

image: docker:20.10  # To run all jobs in this pipeline, use a latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image which contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

# Software Component Analysis
sca-frontend:
  stage: build
  image: node:alpine3.10
  script:
    - npm install
    - npm install -g retire # Install retirejs npm package.
    - retire --outputformat json --outputpath retirejs-report.json --severity high
  artifacts:
    paths: [retirejs-report.json]
    when: always # What is this for?
    expire_in: one week

sca-backend:
  stage: build
  script:
    - docker pull hysnsec/safety
    - docker run --rm -v $(pwd):/src hysnsec/safety check -r requirements.txt --json > oast-results.json
  artifacts:
    paths: [oast-results.json]
    when: always # What does this do?
  allow_failure: true #<--- allow the build to fail but don't mark it as such

# Git Secrets Scanning
secrets-scanning:
  stage: build
  script:
    - docker run -v $(pwd):/src --rm hysnsec/trufflehog filesystem --directory=/src --json | tee trufflehog-output.json
  artifacts:
    paths: [trufflehog-output.json]
    when: always  # What is this for?
    expire_in: one week
  allow_failure: true

# Static Application Security Testing
sast:
  stage: build
  script:
    - docker pull hysnsec/bandit  # Download bandit docker container
    # Run docker container, please refer docker security course, if this doesn't make sense to you.
    - docker run --user $(id -u):$(id -g) -v $(pwd):/src --rm hysnsec/bandit -r /src -f json -o /src/bandit-output.json
  artifacts:
    paths: [bandit-output.json]
    when: always
  allow_failure: true   #<--- allow the build to fail but don't mark it as such

# Dynamic Application Security Testing
nikto:
  stage: integration
  script:
    - docker pull hysnsec/nikto
    - docker run --rm -v $(pwd):/tmp hysnsec/nikto -h prod-8lw53ql9 -o /tmp/nikto-output.xml
  artifacts:
    paths: [nikto-output.xml]
    when: always

sslscan:
  stage: integration
  script:
    - docker pull hysnsec/sslyze
    - docker run --rm -v $(pwd):/tmp hysnsec/sslyze prod-8lw53ql9.lab.practical-devsecops.training:443 --json_out /tmp/sslyze-output.json
  artifacts:
    paths: [sslyze-output.json]
    when: always

nmap:
  stage: integration
  script:
    - docker pull hysnsec/nmap
    - docker run --rm -v $(pwd):/tmp hysnsec/nmap prod-8lw53ql9 -oX /tmp/nmap-output.xml
  artifacts:
    paths: [nmap-output.xml]
    when: always

zap-baseline:
  stage: integration
  script:
    - docker pull softwaresecurityproject/zap-stable:2.13.0
    - docker run --user $(id -u):$(id -g) --rm -v $(pwd):/zap/wrk:rw softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training -J zap-output.json
  after_script:
    - docker rmi softwaresecurityproject/zap-stable:2.13.0  # clean up the image to save the disk space
  artifacts:
    paths: [zap-output.json]
    when: always # What does this do?
  allow_failure: true

# Infrastructure as Code
# PLEASE ENSURE YOU HAVE SETUP THE ENVIRONMENT VARIABLES AND NEEDED FILES APPROPRIATELY
ansible-hardening:
  stage: prod
  image: willhallonline/ansible:2.9-ubuntu-18.04
  before_script:
    - mkdir -p ~/.ssh
    - echo "$DEPLOYMENT_SERVER_SSH_PRIVKEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval "$(ssh-agent -s)"
    - ssh-add ~/.ssh/id_rsa
    - ssh-keyscan -t rsa $DEPLOYMENT_SERVER >> ~/.ssh/known_hosts
  script:
    - echo -e "[prod]\n$DEPLOYMENT_SERVER" >> inventory.ini
    - ansible-galaxy install dev-sec.os-hardening
    - ansible-playbook -i inventory.ini ansible-hardening.yml

# Compliance as Code
# PLEASE ENSURE YOU HAVE SETUP THE ENVIRONMENT VARIABLES AND NEEDED FILES APPROPRIATELY
inspec:
  stage: prod
  only:
    - "main"
  environment: production
  before_script:
    - mkdir -p ~/.ssh
    - echo "$DEPLOYMENT_SERVER_SSH_PRIVKEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval "$(ssh-agent -s)"
    - ssh-add ~/.ssh/id_rsa
    - ssh-keyscan -t rsa $DEPLOYMENT_SERVER >> ~/.ssh/known_hosts
  script:
    - docker run --rm -v ~/.ssh:/root/.ssh -v $(pwd):/share hysnsec/inspec exec https://github.com/dev-sec/linux-baseline.git -t ssh://root@$DEPLOYMENT_SERVER -i ~/.ssh/id_rsa --chef-license accept --reporter json:inspec-output.json
  artifacts:
    paths: [inspec-output.json]
    when: always

# Vulnerability Management(VM)
sast-with-vm:
  stage: build
  before_script:
    - apk add py-pip py-requests curl
    - curl https://gitlab.practical-devsecops.training/-/snippets/3/raw -o upload-results.py
  script:
    - docker pull hysnsec/bandit  # Download bandit docker container
    - docker run --user $(id -u):$(id -g) -v $(pwd):/src --rm hysnsec/bandit -r /src -f json -o /src/bandit-output.json
  after_script:
    - python3 upload-results.py --host $DOJO_HOST --api_key $DOJO_API_TOKEN --engagement_id 1 --product_id 1 --lead_id 1 --environment "Production" --result_file bandit-output.json --scanner "Bandit Scan"
  artifacts:
    paths: [bandit-output.json]
    when: always




----Practice Exam----
--CDP Practice Exam Solutions--
#Challenge 1 (25 points)
#Implement SCA, SAST, DAST for the django.nv project
#Ensure all the best practices covered in the course videos, labs and mattermost discussion are being implemented
#Please embed these tests in CI/CD pipeline

#Challenge 2 (25 points)
#Harden the production machine
#Ensure it stays compliant with linux-baseline Inspec Profile
#Embed these tests as part of CI/CD pipeline
#Let’s try to solve these challenges in the next page.


*Challenge 1*
*Task 1*
#Implement SCA, SAST, DAST for the django.nv project
#As per the best practices, we need to test DevSecOps tools locally before embedding them into CI/CD pipeline.

git clone http://gitlab-ce-8lw53ql9.lab.practical-devsecops.training/root/django-nv.git
cd django-nv

*Software Component Analysis (SCA)*
#For front-end:
mkdir -p /etc/apt/keyrings
curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
NODE_MAJOR=20
echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | tee /etc/apt/sources.list.d/nodesource.list
apt update
apt install nodejs -y
npm install -g retire # Install retirejs npm package
retire --outputformat json --outputpath retirejs-report.json --severity high

#For backend:
docker run --rm -v $(pwd):/src hysnsec/safety check -r requirements.txt --json > oast-results.json

*Static Application Security Testing (SAST)*
#For secrets-scanning:
docker run --rm -v $(pwd):/src hysnsec/trufflehog filesystem --directory=/src --json | tee trufflehog-output.json

#For code analysis:
docker run --user $(id -u):$(id -g) --rm -v $(pwd):/src hysnsec/bandit -r /src -f json -o /src/bandit-output.json

*Dynamic Application Security Testing (DAST)*
#SSL Scan
docker run --rm -v $(pwd):/tmp hysnsec/sslyze prod-8lw53ql9.lab.practical-devsecops.training:443 --json_out /tmp/sslyze-output.json

#Nmap
docker run --rm -v $(pwd):/tmp hysnsec/nmap prod-8lw53ql9 -oX /tmp/nmap-output.xml

#ZAP Baseline
docker run --user $(id -u):$(id -g) -w /zap -v $(pwd):/zap/wrk:rw --rm softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training -J zap-output.json


*Task 2*
#Please embed these tests in CI/CD pipeline

image: docker:20.10

services:
  - docker:dind

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py check

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

# Software Component Analysis
sca-frontend:
  stage: build
  image: node:alpine3.10
  script:
    - npm install
    - npm install -g retire # Install retirejs npm package.
    - retire --outputformat json --outputpath retirejs-report.json --severity high
  artifacts:
    paths: [retirejs-report.json]
    when: always # What is this for?
    expire_in: one week
  allow_failure: true #<--- allow the build to fail but don't mark it as such  

sca-backend:
  stage: build
  script:
    - docker pull hysnsec/safety
    - docker run --rm -v $(pwd):/src hysnsec/safety check -r requirements.txt --json > oast-results.json
  artifacts:
    paths: [oast-results.json]
    when: always # What does this do?
  allow_failure: true #<--- allow the build to fail but don't mark it as such

# Git Secrets Scanning
secrets-scanning:
  stage: build
  script:
    - docker run -v $(pwd):/src --rm hysnsec/trufflehog filesystem --directory=/src --json | tee trufflehog-output.json
  artifacts:
    paths: [trufflehog-output.json]
    when: always  # What is this for?
    expire_in: one week
  allow_failure: true

# Static Application Security Testing
sast:
  stage: build
  script:
    - docker pull hysnsec/bandit  # Download bandit docker container
    # Run docker container, please refer docker security course, if this doesn't make sense to you.
    - docker run --user $(id -u):$(id -g) -v $(pwd):/src --rm hysnsec/bandit -r /src -f json -o /src/bandit-output.json
  artifacts:
    paths: [bandit-output.json]
    when: always
  allow_failure: true   #<--- allow the build to fail but don't mark it as such

# Dynamic Application Security Testing
nikto:
  stage: integration
  script:
    - docker pull hysnsec/nikto
    - docker run --rm -v $(pwd):/tmp hysnsec/nikto -h prod-8lw53ql9 -o /tmp/nikto-output.xml
  artifacts:
    paths: [nikto-output.xml]
    when: always

sslscan:
  stage: integration
  script:
    - docker pull hysnsec/sslyze
    - docker run --rm -v $(pwd):/tmp hysnsec/sslyze prod-8lw53ql9.lab.practical-devsecops.training:443 --json_out /tmp/sslyze-output.json
  artifacts:
    paths: [sslyze-output.json]
    when: always

nmap:
  stage: integration
  script:
    - docker pull hysnsec/nmap
    - docker run --rm -v $(pwd):/tmp hysnsec/nmap prod-8lw53ql9 -oX /tmp/nmap-output.xml
  artifacts:
    paths: [nmap-output.xml]
    when: always

zap-baseline:
  stage: integration
  script:
    - docker pull softwaresecurityproject/zap-stable:2.13.0
    - docker run --user $(id -u):$(id -g) --rm -v $(pwd):/zap/wrk:rw softwaresecurityproject/zap-stable:2.13.0 zap-baseline.py -t https://prod-8lw53ql9.lab.practical-devsecops.training -J zap-output.json
  after_script:
    - docker rmi softwaresecurityproject/zap-stable:2.13.0  # clean up the image to save the disk space
  artifacts:
    paths: [zap-output.json]
    when: always # What does this do?
  allow_failure: true


*Task 3*
#Ensure all the best practices covered in the course videos, labs and mattermost discussion are being implemented

#We tried to implement all the best practices we have learned in the course
#1. Tested the tools locally before embedding in the pipeline
#2. Ensured the scans finish within 10 minutes
#3. Ensured they each run in their own jobs
#4. We saved the output in a file
#5. We didn’t fail the builds


#Challenge 2
*Task 1*
#Harden the production machine
#As per the best practices, we need to test DevSecOps tools locally before embedding them into CI/CD pipeline.

*IaC*
#We need the inventory.ini first, so lets create one
cat > inventory.ini <<EOL
# DevSecOps Studio Inventory
[prod]
prod-8lw53ql9

EOL

#Let’s download the role
ansible-galaxy install dev-sec.os-hardening

#Next, let’s create a playbook
cat > ansible-hardening.yml <<EOL
---
- name: Playbook to harden Ubuntu OS.
  hosts: prod
  remote_user: root
  become: yes

  roles:
    - dev-sec.os-hardening

EOL

#Let’s run the pipeline now.
ansible-playbook -i inventory.ini ansible-hardening.yml


*Task 2*
#Ensure it stays compliant with linux-baseline Inspec Profile

#We can verify if the machine stays hardened using Inspec.
#NOTE: /share directory should be used when using hysnsec/inspec image. Because it’s a custom image adding another directory would not work when you are saving the inspec output.
docker run --rm -v ~/.ssh:/root/.ssh -v $(pwd):/share hysnsec/inspec exec https://github.com/dev-sec/linux-baseline.git -t ssh://root@$DEPLOYMENT_SERVER -i /root/.ssh/id_rsa --chef-license accept --reporter json:/share/inspec-output.json


*Task 3*
#Embed these tests as part of CI/CD pipeline

#Next, we need to create a CI/CD pipeline by replacing the .gitlab-ci.yml file content with the below Gitlab CI script. Click on the Edit button to start replacing the content (use Control+A and Control+V).

#Make sure you have added the necessary variables into your project (Settings > CI/CD) such as $DEPLOYMENT_SERVER_SSH_PRIVKEY and $DEPLOYMENT_SERVER.
ssh root@prod-8lw53ql9
more /root/.ssh/id_rsa

image: docker:20.10

services:
  - docker:dind

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

# Infrastructure as Code
# PLEASE ENSURE YOU HAVE SETUP THE ENVIRONMENT VARIABLES AND NEEDED FILES APPROPRIATELY
ansible-hardening:
  stage: prod
  image: willhallonline/ansible:2.9-ubuntu-18.04
  before_script:
    - mkdir -p ~/.ssh
    - echo "$DEPLOYMENT_SERVER_SSH_PRIVKEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval "$(ssh-agent -s)"
    - ssh-add ~/.ssh/id_rsa
    - ssh-keyscan -t rsa $DEPLOYMENT_SERVER >> ~/.ssh/known_hosts
  script:
    - echo -e "[prod]\n$DEPLOYMENT_SERVER" >> inventory.ini
    - ansible-galaxy install dev-sec.os-hardening
    - ansible-playbook -i inventory.ini ansible-hardening.yml

# Compliance as Code
# PLEASE ENSURE YOU HAVE SETUP THE ENVIRONMENT VARIABLES AND NEEDED FILES APPROPRIATELY
inspec:
  stage: prod
  only:
    - "main"
  environment: production
  before_script:
    - mkdir -p ~/.ssh
    - echo "$DEPLOYMENT_SERVER_SSH_PRIVKEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval "$(ssh-agent -s)"
    - ssh-add ~/.ssh/id_rsa
    - ssh-keyscan -t rsa $DEPLOYMENT_SERVER >> ~/.ssh/known_hosts
  script:
    - docker run --rm -v ~/.ssh:/root/.ssh -v $(pwd):/share hysnsec/inspec exec https://github.com/dev-sec/linux-baseline.git -t ssh://root@$DEPLOYMENT_SERVER -i ~/.ssh/id_rsa --chef-license accept --reporter json:inspec-output.json
  artifacts:
    paths: [inspec-output.json]
    when: always
